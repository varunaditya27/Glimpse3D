<div align="center">

# **âœ¨ Glimpse3D**

### **AI System for Highâ€‘Quality 3D Models From a Single Image**

Transform *one photo* into a **clean, detailed, continuously improving 3D model** using modern AI.

**Zeroâ€‘123 Ã— MiDaS Ã— Gaussian Splatting Ã— SDXL Ã— Our Novel Refinement Module**

</div>

---

# **ğŸ“Œ Overview**

Glimpse3D is a full-stack AI system that converts a **single 2D image** into a **highâ€‘quality 3D Gaussian Splat model**, and then lets the user **continuously enhance the 3D model** with one click.

It merges:

* **Fast singleâ€‘image 3D reconstruction** (TripoSR / LGM)
* **Multiâ€‘view inference** (Zeroâ€‘123)
* **Depth estimation** (MiDaS)
* **3D representation** (Gaussian Splatting via gsplat)
* **Diffusionâ€‘based texture enhancement** (SDXL + ControlNet)
* **A novel refinement module** (backâ€‘projecting enhanced views into 3D)

This makes Glimpse3D both:

* a **research platform** for multiâ€‘view consistency & refinement, and
* a **demo-ready product** for designers, students, and developers.

---

# **ğŸŒŸ Key Features**

### **âœ” Single Image â†’ Coarse 3D Model**

Generate a base 3D Gaussian Splat model in **5â€“10 seconds**.

### **âœ” Multiâ€‘View Understanding (Zeroâ€‘123)**

Optionally synthesize novel views from a single image to infer unseen sides.

### **âœ” Depthâ€‘Aware Corrections (MiDaS)**

Use depth maps to understand geometry and guide refinements.

### **âœ” Oneâ€‘Click Enhancement (SDXL + ControlNet)**

Enhance any view of the model with diffusion â€” sharper textures, improved realism.

### **âœ” Patentâ€‘Ready Backâ€‘Projection**

AIâ€‘enhanced 2D views are projected back into the 3D splat model.

### **âœ” Continuous Improvement Loop**

Each enhancement improves the 3D model further.

### **âœ” Full Web-Based Workspace**

React + Three.js frontend with a sleek, premium UI.

---

# **ğŸ§  Architecture**

```
Single Image
     â†“
Coarse 3D Reconstruction (TripoSR / LGM)
     â†“
Gaussian Splat Model (gsplat)
     â†“
[Optional] Zeroâ€‘123 Multiâ€‘View Generation
     â†“
Depth Maps via MiDaS
     â†“
Enhancement Loop:
 1. Render View
 2. Enhance with SDXL + ControlNet
 3. Backâ€‘Project into 3D
     â†“
Refined 3D Model â†’ Export (.ply / .splat / .glb)
```

---

# **ğŸ“ Project Structure**

A clean and scalable monorepo structure:

```
Glimpse3D/
â”œâ”€â”€ frontend/               # React + Three.js UI
â”œâ”€â”€ backend/                # FastAPI + PyTorch pipeline
â”œâ”€â”€ ai_modules/             # Zero123, MiDaS, SDXL, gsplat
â”œâ”€â”€ research/               # Experiments, notebooks, metrics
â”œâ”€â”€ model_checkpoints/      # Pretrained AI models
â”œâ”€â”€ assets/                 # Sample inputs/outputs, HDRIs, icons
â”œâ”€â”€ docker/                 # Deployment files
â”œâ”€â”€ scripts/                # Setup/automation
â””â”€â”€ docs/                   # Architecture diagrams, notes
```

---

# **ğŸš€ Getting Started**

## **1. Clone the repo**

```
$ git clone https://github.com/your-org/glimpse3d
$ cd glimpse3d
```

## **2. Download Models**

Run the helper script:

```
$ python scripts/download_models.py
```

This grabs:

* Zeroâ€‘123
* MiDaS
* TripoSR / LGM
* SDXL
* ControlNet

## **3. Install Backend Dependencies**

```
$ cd backend
$ pip install -r requirements.txt
```

## **4. Start Backend (FastAPI)**

```
$ uvicorn app.main:app --reload
```

## **5. Install Frontend**

```
$ cd ../frontend
$ npm install
$ npm run dev
```

## **6. Open App**

Visit:

```
http://localhost:5173/
```

---

# **ğŸ§© Core Components**

### **Backend Services**

* `zero123_service.py` â€” novelâ€‘view synthesis
* `depth_service.py` â€” MiDaS inference
* `gsplat_service.py` â€” recon + rendering
* `diffusion_service.py` â€” SDXL enhancement
* `backprojection.py` â€” â˜… novel contribution: update splats

### **Frontend**

* 3D Viewer (Three.js / React Three Fiber)
* Enhance button workflow
* Upload â†’ Generate â†’ Enhance â†’ Export

### **Refinement Module (MVCRM)**

* Depth consistency check
* Normal smoothing
* CLIP feature comparison (optional)
* Weighted fusion logic

---

# **ğŸ“Š Research Components**

Located in `/research/`:

* Zeroâ€‘123 baseline reproduction
* Multiâ€‘view inconsistency analysis
* Depth variance evaluation
* CLIP similarity evaluation
* Gaussian Splatting before/after comparisons
* Ablation studies

These enable publication-ready results.

---

# **ğŸ›  Tech Stack**

### **Frontend**

* React + Vite
* Three.js + React Three Fiber
* Framer Motion

### **Backend**

* FastAPI
* PyTorch
* gsplat / Gaussian Splatting
* SDXL + ControlNet

### **AI Modules**

* Zeroâ€‘123
* MiDaS
* TripoSR / LGM
* CLIP

---

# **ğŸ“¦ Export Formats**

The refined 3D model can be exported as:

* `.ply`
* `.splat`
* `.glb`

---

# **ğŸ§ª Testing**

```
backend/tests/
â”œâ”€â”€ test_zero123.py
â”œâ”€â”€ test_depth.py
â”œâ”€â”€ test_diffusion.py
â”œâ”€â”€ test_pipeline.py
â””â”€â”€ test_api.py
```

---

# **ğŸ“œ License**

MIT (or custom, depending on your IP/patent plan)

---

<div align="center">

# **âœ¨ Glimpse3D â€” Turning a Single Glimpse Into a Full 3D Reality**

Feel free to contribute, open issues, or build on top of this system.

</div>
