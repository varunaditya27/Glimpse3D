<div align="center">

# **âœ¨ Glimpse3D**

### **AI System for Highâ€‘Quality 3D Gaussian Splats From a Single Image**

Transform *one photo* into a **production-ready 3D Gaussian Splat model** using state-of-the-art AI.

**TripoSR Ã— SyncDreamer Ã— SDXL Lightning Ã— gsplat Ã— MiDaS Ã— MVCRM**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/varunaditya27/Glimpse3D/blob/main/notebooks/Glimpse3D_Master_Pipeline.ipynb)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

</div>

---

# **ğŸ“Œ Overview**

Glimpse3D is a **production-ready AI pipeline** that converts a **single 2D image** into a **high-quality 3D Gaussian Splat model** in approximately 30 minutes on a free Google Colab T4 GPU.

### **Complete Pipeline**

```
ğŸ“· Input Image
    â†“
ğŸ”· TripoSR (30s) â†’ Initial 3D Mesh â†’ Gaussian Points
    â†“
ğŸ¨ SyncDreamer (2-3min) â†’ 16 Consistent Multi-View Images
    â†“  
âœ¨ SDXL Lightning + ControlNet â†’ Enhanced Views (Optional)
    â†“
ğŸ”® gsplat Optimization (5min) â†’ Refined Gaussians
    â†“
ğŸ”„ MVCRM â†’ Multi-View Consistent Refinement
    â†“
ğŸ† Final 3D Gaussian Splat Output (.ply, .glb, .mp4)
```

### **AI Modules Integrated**

| Module | Purpose | Source | Status |
|--------|---------|--------|--------|
| **TripoSR** | Fast single-image 3D reconstruction | [VAST-AI-Research](https://github.com/VAST-AI-Research/TripoSR) | âœ… Verified |
| **SyncDreamer** | Multi-view consistent image generation | [liuyuan-pal](https://github.com/liuyuan-pal/SyncDreamer) | âœ… Verified |
| **SDXL Lightning** | 4-step diffusion enhancement | [ByteDance](https://huggingface.co/ByteDance/SDXL-Lightning) | âœ… Verified |
| **gsplat** | Gaussian splatting optimization | [nerfstudio-project](https://github.com/nerfstudio-project/gsplat) | âœ… Verified |
| **MiDaS** | Monocular depth estimation | [isl-org](https://github.com/isl-org/MiDaS) | âœ… Integrated |
| **MVCRM** | Multi-view consistency refinement | Custom | âœ… Integrated |

This makes Glimpse3D both:

* a **research platform** for multi-view consistency & 3D reconstruction, and
* a **production-ready system** for designers, students, and developers.

---

# **ğŸš€ Quick Start (Google Colab)**

The fastest way to try Glimpse3D is via our **production-ready Colab notebook**:

1. **Open the notebook**: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/varunaditya27/Glimpse3D/blob/main/notebooks/Glimpse3D_Master_Pipeline.ipynb)
2. **Select GPU runtime**: Runtime â†’ Change runtime type â†’ T4 GPU
3. **Run all cells**: Runtime â†’ Run all
4. **Upload your image** when prompted
5. **Download results** (~30 minutes total)

### **Requirements**
- Google Colab with **T4 GPU** (free tier) or **A100** (faster)
- ~12GB VRAM peak usage
- ~30 minutes total runtime

---

# **ğŸŒŸ Key Features**

### **âœ” Single Image â†’ 3D Gaussian Splats**

Generate a complete 3D Gaussian Splat model from just one photo.

### **âœ” Multiâ€‘View Consistency (SyncDreamer)**

Generate 16 geometrically consistent views at 30Â° elevation with 22.5Â° azimuth spacing.

### **âœ” Lightning-Fast Enhancement (SDXL Lightning)**

4-step diffusion enhancement for sharper textures and improved realism.

### **âœ” Production-Ready gsplat Integration**

Optimized Gaussian splatting with correct opacity shapes and quaternion conventions.

### **âœ” Depthâ€‘Aware Processing (MiDaS)**

Monocular depth estimation for geometry-aware refinement.

### **âœ” Multi-View Consistent Refinement (MVCRM)**

Novel refinement module with depth consistency, normal smoothing, and feature fusion.

### **âœ” Multiple Export Formats**

Export as `.ply` (Gaussian Splats), `.glb`/`.obj` (mesh), and `.mp4` (360Â° video).

---

# **ğŸ§  Architecture**

```
Single Image
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: TripoSR                                           â”‚
â”‚  - Background removal (rembg)                               â”‚
â”‚  - 3D mesh reconstruction (~30s)                            â”‚
â”‚  - Mesh â†’ Gaussian point cloud conversion                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: SyncDreamer                                       â”‚
â”‚  - 16 consistent multi-view images                          â”‚
â”‚  - Fixed 30Â° elevation, 22.5Â° azimuth spacing               â”‚
â”‚  - Synchronized attention for consistency                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 3: SDXL Lightning (Optional)                         â”‚
â”‚  - 4-step diffusion enhancement                             â”‚
â”‚  - guidance_scale=0, timestep_spacing="trailing"            â”‚
â”‚  - Sharper textures, improved details                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 4: gsplat Optimization                               â”‚
â”‚  - Multi-view photometric loss                              â”‚
â”‚  - 1000+ iterations of gradient descent                     â”‚
â”‚  - Opacity shape: [N], quaternions: wxyz format             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 5: MVCRM Refinement (Optional)                       â”‚
â”‚  - Depth consistency checking                               â”‚
â”‚  - Normal smoothing                                         â”‚
â”‚  - Feature-based fusion                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
Final Output: .ply (Gaussians) + .glb (mesh) + .mp4 (video)
```

---

# **ğŸ“ Project Structure**

```
Glimpse3D/
â”œâ”€â”€ notebooks/              # ğŸ““ Colab notebooks (START HERE)
â”‚   â”œâ”€â”€ Glimpse3D_Master_Pipeline.ipynb    # Complete end-to-end pipeline
â”‚   â”œâ”€â”€ Glimpse3D_TripoSR_Reconstruction.ipynb
â”‚   â”œâ”€â”€ Glimpse3D_SyncDreamer_Inference.ipynb
â”‚   â”œâ”€â”€ Glimpse3D_Diffusion_Enhancement.ipynb
â”‚   â”œâ”€â”€ Glimpse3D_GSplat_Optimization.ipynb
â”‚   â””â”€â”€ Glimpse3D_MVCRM_Refinement.ipynb
â”‚
â”œâ”€â”€ ai_modules/             # ğŸ§  Core AI modules
â”‚   â”œâ”€â”€ sync_dreamer/       # SyncDreamer multi-view generation
â”‚   â”œâ”€â”€ gsplat/             # Gaussian splatting optimization
â”‚   â”œâ”€â”€ midas_depth/        # MiDaS depth estimation
â”‚   â”œâ”€â”€ diffusion/          # SDXL Lightning enhancement
â”‚   â”œâ”€â”€ refine_module/      # MVCRM refinement
â”‚   â””â”€â”€ zero123/            # Zero-123 (alternative to SyncDreamer)
â”‚
â”œâ”€â”€ frontend/               # ğŸ–¥ï¸ React + Three.js UI
â”œâ”€â”€ backend/                # âš™ï¸ FastAPI server
â”œâ”€â”€ model_checkpoints/      # ğŸ“¦ Pretrained model weights
â”œâ”€â”€ assets/                 # ğŸ–¼ï¸ Sample inputs/outputs
â”œâ”€â”€ docs/                   # ğŸ“š Documentation
â”‚   â”œâ”€â”€ CRITICAL_REVIEW_REPORT.md   # Production readiness analysis
â”‚   â””â”€â”€ pipeline_flow.md
â”œâ”€â”€ scripts/                # ğŸ”§ Setup & automation
â”œâ”€â”€ research/               # ğŸ”¬ Experiments & metrics
â””â”€â”€ docker/                 # ğŸ³ Deployment files
```

---

# **ğŸš€ Local Installation**

## **1. Clone the repo**

```bash
git clone https://github.com/varunaditya27/Glimpse3D.git
cd Glimpse3D
```

## **2. Create environment**

```bash
# Using conda (recommended)
conda create -n glimpse3d python=3.10
conda activate glimpse3d

# Install PyTorch with CUDA
pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118
```

## **3. Install dependencies**

```bash
# Core dependencies
pip install transformers==4.40.0 diffusers==0.27.2 accelerate==0.28.0
pip install omegaconf==2.3.0 einops==0.7.0 pytorch-lightning==1.9.5
pip install gsplat==1.2.0 trimesh==4.2.0 rembg[gpu]==2.0.55

# SyncDreamer dependencies
pip install git+https://github.com/openai/CLIP.git@a1d071733d7111c9c014f024669f959182114e33
```

## **4. Download model checkpoints**

```bash
python scripts/download_models.py
```

## **5. Run the pipeline**

```bash
# Option A: Jupyter notebook
jupyter notebook notebooks/Glimpse3D_Master_Pipeline.ipynb

# Option B: Backend API
cd backend
uvicorn app.main:app --reload
```

---

# **ğŸ§© AI Module Details**

### **TripoSR** â€” Fast 3D Reconstruction
- **Source**: [VAST-AI-Research/TripoSR](https://github.com/VAST-AI-Research/TripoSR)
- **Model**: `stabilityai/TripoSR` on HuggingFace
- **API**: `TSR.from_pretrained()`, `remove_background()`, `resize_foreground()`
- **Output**: 3D mesh with vertex colors

### **SyncDreamer** â€” Multi-View Generation
- **Source**: [liuyuan-pal/SyncDreamer](https://github.com/liuyuan-pal/SyncDreamer) (ICLR 2024 Spotlight)
- **Config**: 16 views, 30Â° elevation, 22.5Â° azimuth spacing
- **API**: `prepare_inputs()`, `SyncDDIMSampler`, `model.sample()`
- **Output**: 16 consistent 256Ã—256 images

### **SDXL Lightning** â€” Fast Enhancement
- **Source**: [ByteDance/SDXL-Lightning](https://huggingface.co/ByteDance/SDXL-Lightning)
- **Config**: 4-step UNet, `guidance_scale=0`, `timestep_spacing="trailing"`
- **API**: `UNet2DConditionModel.from_config()` + `load_state_dict()`
- **Output**: Enhanced images with sharper details

### **gsplat** â€” Gaussian Splatting
- **Source**: [nerfstudio-project/gsplat](https://github.com/nerfstudio-project/gsplat)
- **Version**: 1.2.0
- **API**: `rasterization(means, quats, scales, opacities, colors, viewmats, Ks, width, height)`
- **Critical**: Opacity shape must be `[N]` (1D), quaternions in wxyz format

### **MVCRM** â€” Refinement Module
- **Location**: `ai_modules/refine_module/`
- **Components**: Depth consistency, normal smoothing, feature fusion
- **Purpose**: Multi-view consistent refinement of Gaussian splats

---

# **ï¿½ Notebooks**

| Notebook | Purpose | Runtime |
|----------|---------|---------|
| `Glimpse3D_Master_Pipeline.ipynb` | **Complete end-to-end pipeline** | ~30 min |
| `Glimpse3D_TripoSR_Reconstruction.ipynb` | TripoSR mesh generation only | ~2 min |
| `Glimpse3D_SyncDreamer_Inference.ipynb` | Multi-view generation only | ~5 min |
| `Glimpse3D_Diffusion_Enhancement.ipynb` | SDXL enhancement only | ~3 min |
| `Glimpse3D_GSplat_Optimization.ipynb` | Gaussian optimization only | ~10 min |
| `Glimpse3D_MVCRM_Refinement.ipynb` | MVCRM refinement only | ~5 min |

---

# **ğŸ“Š Research Components**

Located in `/research/`:

* Multi-view consistency analysis
* Depth variance evaluation
* CLIP similarity metrics
* Gaussian Splatting quality comparisons
* Ablation studies on pipeline components

---

# **ğŸ›  Tech Stack**

### **AI / ML**
- PyTorch 2.0.1 + CUDA 11.8
- gsplat 1.2.0
- Diffusers 0.27.2
- PyTorch Lightning 1.9.5

### **Frontend**
- React + Vite
- Three.js + React Three Fiber
- Framer Motion

### **Backend**
- FastAPI
- Uvicorn

---

# **ğŸ“¦ Output Formats**

| Format | Description | Viewer |
|--------|-------------|--------|
| `.ply` | Gaussian Splat model | [SuperSplat](https://playcanvas.com/supersplat/editor), [Luma AI](https://lumalabs.ai/) |
| `.glb` | 3D mesh (GLTF binary) | [glTF Viewer](https://gltf-viewer.donmccurdy.com/), Blender |
| `.obj` | 3D mesh (Wavefront) | Any 3D software |
| `.mp4` | 360Â° turntable video | Any video player |

---

# **ğŸ§ª Testing**

```bash
# Run backend tests
cd backend
pytest tests/

# Verify full pipeline
python scripts/verify_full_stack.py

# Test individual modules
python ai_modules/midas_depth/test_depth.py
python ai_modules/refine_module/test_refine.py
```

---

# **âš ï¸ Known Issues & Solutions**

| Issue | Solution |
|-------|----------|
| CUDA OOM on T4 | Reduce `BATCH_VIEW_NUM` to 2, `MC_RESOLUTION` to 192 |
| gsplat shape error | Ensure opacity is `[N]` shape, not `[N,1]` |
| SyncDreamer view mismatch | Use 30Â° elevation for all 16 views, 22.5Â° azimuth spacing |
| SDXL Lightning artifacts | Set `guidance_scale=0`, use `timestep_spacing="trailing"` |

See [CRITICAL_REVIEW_REPORT.md](docs/CRITICAL_REVIEW_REPORT.md) for detailed production readiness analysis.

---

# **ğŸ¤ Contributing**

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

# **ğŸ“œ License**

MIT License - see [LICENSE](LICENSE) for details.

---

# **ğŸ™ Acknowledgments**

- [TripoSR](https://github.com/VAST-AI-Research/TripoSR) by VAST-AI-Research & Stability AI
- [SyncDreamer](https://github.com/liuyuan-pal/SyncDreamer) by Yuan Liu et al. (ICLR 2024)
- [SDXL Lightning](https://huggingface.co/ByteDance/SDXL-Lightning) by ByteDance
- [gsplat](https://github.com/nerfstudio-project/gsplat) by Nerfstudio Project
- [MiDaS](https://github.com/isl-org/MiDaS) by Intel ISL

---

<div align="center">

# **âœ¨ Glimpse3D**

### **Turning a Single Glimpse Into a Full 3D Reality**

[Open in Colab](https://colab.research.google.com/github/varunaditya27/Glimpse3D/blob/main/notebooks/Glimpse3D_Master_Pipeline.ipynb) Â· [Report Bug](https://github.com/varunaditya27/Glimpse3D/issues) Â· [Request Feature](https://github.com/varunaditya27/Glimpse3D/issues)

[Open in Colab](https://colab.research.google.com/github/varunaditya27/Glimpse3D/blob/main/notebooks/Glimpse3D_Master_Pipeline.ipynb) Â· [Report Bug](https://github.com/varunaditya27/Glimpse3D/issues) Â· [Request Feature](https://github.com/varunaditya27/Glimpse3D/issues)

</div>