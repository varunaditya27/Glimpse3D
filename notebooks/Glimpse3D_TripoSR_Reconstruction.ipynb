{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a8f709",
   "metadata": {},
   "source": [
    "# üî∑ Glimpse3D - TripoSR 3D Reconstruction\n",
    "\n",
    "**Fast single-image to 3D mesh reconstruction using TripoSR**\n",
    "\n",
    "This notebook generates the **initial 3D mesh** from a single image in ~0.5 seconds.\n",
    "\n",
    "## Pipeline Role\n",
    "```\n",
    "[This Notebook] ‚Üí Mesh ‚Üí Sample Points ‚Üí Gaussian Splats ‚Üí SyncDreamer ‚Üí Refinement\n",
    "```\n",
    "\n",
    "## Requirements\n",
    "- Google Colab with **T4 GPU** (free tier works!)\n",
    "- ~6GB VRAM for default settings\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25aa652",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check GPU & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check environment\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Colab: {IN_COLAB}\")\n",
    "\n",
    "# Check GPU\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f89301",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3048ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install TripoSR dependencies\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118 --quiet\n",
    "!pip install transformers accelerate huggingface_hub --quiet\n",
    "!pip install omegaconf einops trimesh rembg[gpu] Pillow --quiet\n",
    "!pip install xatlas plyfile --quiet\n",
    "\n",
    "# Install torchmcubes for mesh extraction\n",
    "!pip install git+https://github.com/tatsy/torchmcubes.git --quiet\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e71e54e",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Clone TripoSR Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "TRIPOSR_PATH = \"/content/TripoSR\"\n",
    "\n",
    "if not os.path.exists(TRIPOSR_PATH):\n",
    "    print(\"üì• Cloning TripoSR...\")\n",
    "    !git clone https://github.com/VAST-AI-Research/TripoSR.git {TRIPOSR_PATH}\n",
    "else:\n",
    "    print(\"‚úÖ TripoSR already cloned\")\n",
    "\n",
    "# Add to path\n",
    "if TRIPOSR_PATH not in sys.path:\n",
    "    sys.path.insert(0, TRIPOSR_PATH)\n",
    "\n",
    "os.chdir(TRIPOSR_PATH)\n",
    "print(f\"üìÇ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65323f7d",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Load TripoSR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3868636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tsr.system import TSR\n",
    "\n",
    "# Set device\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load model (downloads from HuggingFace automatically)\n",
    "print(\"\\nüì• Loading TripoSR model (first run downloads ~1GB)...\")\n",
    "model = TSR.from_pretrained(\n",
    "    \"stabilityai/TripoSR\",\n",
    "    config_name=\"config.yaml\",\n",
    "    weight_name=\"model.ckpt\",\n",
    ")\n",
    "\n",
    "# Optimize for T4 GPU\n",
    "model.renderer.set_chunk_size(8192)  # Balance speed/memory\n",
    "model.to(device)\n",
    "print(\"‚úÖ Model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8494b864",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Upload Your Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12152e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Upload image\n",
    "print(\"üì§ Upload an image (JPG/PNG):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get filename\n",
    "IMAGE_PATH = list(uploaded.keys())[0]\n",
    "print(f\"\\n‚úÖ Uploaded: {IMAGE_PATH}\")\n",
    "\n",
    "# Display\n",
    "img = Image.open(IMAGE_PATH)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(\"Input Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7c4e2",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Preprocess Image (Remove Background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01348bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rembg\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tsr.utils import remove_background, resize_foreground\n",
    "\n",
    "# Settings\n",
    "REMOVE_BG = True  # Set to False if image already has transparent background\n",
    "FOREGROUND_RATIO = 0.85  # How much of image the object should fill\n",
    "\n",
    "# Load image\n",
    "input_image = Image.open(IMAGE_PATH)\n",
    "\n",
    "if REMOVE_BG:\n",
    "    print(\"üîß Removing background...\")\n",
    "    rembg_session = rembg.new_session()\n",
    "    processed_image = remove_background(input_image, rembg_session)\n",
    "    processed_image = resize_foreground(processed_image, FOREGROUND_RATIO)\n",
    "    \n",
    "    # Convert RGBA to RGB with gray background\n",
    "    image_np = np.array(processed_image).astype(np.float32) / 255.0\n",
    "    image_np = image_np[:, :, :3] * image_np[:, :, 3:4] + (1 - image_np[:, :, 3:4]) * 0.5\n",
    "    processed_image = Image.fromarray((image_np * 255.0).astype(np.uint8))\n",
    "else:\n",
    "    processed_image = input_image.convert(\"RGB\")\n",
    "\n",
    "# Save processed\n",
    "processed_image.save(\"/content/processed_input.png\")\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(processed_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Processed Image\")\n",
    "plt.show()\n",
    "print(\"‚úÖ Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcddf6c",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Run TripoSR Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd5ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Settings\n",
    "MC_RESOLUTION = 256  # Marching cubes resolution (higher = more detailed)\n",
    "\n",
    "print(\"üöÄ Running TripoSR inference...\")\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Generate scene codes\n",
    "    scene_codes = model([processed_image], device=device)\n",
    "    \n",
    "    # Extract mesh with vertex colors\n",
    "    meshes = model.extract_mesh(\n",
    "        scene_codes, \n",
    "        has_vertex_color=True, \n",
    "        resolution=MC_RESOLUTION\n",
    "    )\n",
    "\n",
    "mesh = meshes[0]\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Mesh generated in {elapsed:.2f} seconds!\")\n",
    "print(f\"   Vertices: {len(mesh.vertices):,}\")\n",
    "print(f\"   Faces: {len(mesh.faces):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708981c5",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Export Mesh (OBJ & PLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be5f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR = \"/content/triposr_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Export OBJ (with vertex colors)\n",
    "obj_path = f\"{OUTPUT_DIR}/mesh.obj\"\n",
    "mesh.export(obj_path)\n",
    "print(f\"‚úÖ Saved OBJ: {obj_path}\")\n",
    "\n",
    "# Export GLB (for web viewers)\n",
    "glb_path = f\"{OUTPUT_DIR}/mesh.glb\"\n",
    "mesh.export(glb_path)\n",
    "print(f\"‚úÖ Saved GLB: {glb_path}\")\n",
    "\n",
    "# Export PLY (for Gaussian Splatting)\n",
    "ply_path = f\"{OUTPUT_DIR}/mesh.ply\"\n",
    "mesh.export(ply_path)\n",
    "print(f\"‚úÖ Saved PLY: {ply_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5533acd8",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Convert to Gaussian Splat Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plyfile import PlyData, PlyElement\n",
    "\n",
    "def mesh_to_gaussian_ply(mesh, output_path, num_samples=100000):\n",
    "    \"\"\"\n",
    "    Convert trimesh mesh to Gaussian Splat PLY format.\n",
    "    Samples points from mesh surface and initializes Gaussian parameters.\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Sampling {num_samples:,} points from mesh...\")\n",
    "    \n",
    "    # Sample points with colors from mesh\n",
    "    points, face_indices = mesh.sample(num_samples, return_index=True)\n",
    "    \n",
    "    # Get vertex colors for sampled points\n",
    "    if mesh.visual.vertex_colors is not None:\n",
    "        # Interpolate colors from face vertices\n",
    "        face_vertices = mesh.faces[face_indices]\n",
    "        vertex_colors = mesh.visual.vertex_colors[:, :3] / 255.0\n",
    "        \n",
    "        # Simple: use average of face vertex colors\n",
    "        colors = vertex_colors[face_vertices].mean(axis=1)\n",
    "    else:\n",
    "        colors = np.ones((num_samples, 3)) * 0.5  # Gray default\n",
    "    \n",
    "    num_points = len(points)\n",
    "    \n",
    "    # Initialize Gaussian parameters\n",
    "    xyz = points.astype(np.float32)\n",
    "    \n",
    "    # SH DC coefficients (color)\n",
    "    # Formula: RGB = 0.5 + C0 * SH_DC, where C0 = 0.28209\n",
    "    C0 = 0.28209479177387814\n",
    "    features_dc = ((colors - 0.5) / C0).astype(np.float32)\n",
    "    \n",
    "    # SH rest coefficients (15 * 3 = 45 for degree 3)\n",
    "    features_rest = np.zeros((num_points, 45), dtype=np.float32)\n",
    "    \n",
    "    # Opacity (pre-activation, inverse sigmoid)\n",
    "    # sigmoid(2.2) ‚âà 0.9\n",
    "    opacities = np.ones((num_points, 1), dtype=np.float32) * 2.2\n",
    "    \n",
    "    # Scales (pre-activation, log scale)\n",
    "    # exp(-4.6) ‚âà 0.01\n",
    "    scales = np.ones((num_points, 3), dtype=np.float32) * (-4.6)\n",
    "    \n",
    "    # Rotations (quaternion: w, x, y, z)\n",
    "    rotations = np.zeros((num_points, 4), dtype=np.float32)\n",
    "    rotations[:, 0] = 1.0  # Identity rotation\n",
    "    \n",
    "    # Build PLY structure\n",
    "    dtype_full = [\n",
    "        ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),\n",
    "        ('f_dc_0', 'f4'), ('f_dc_1', 'f4'), ('f_dc_2', 'f4'),\n",
    "    ]\n",
    "    \n",
    "    # Add f_rest attributes\n",
    "    for i in range(45):\n",
    "        dtype_full.append((f'f_rest_{i}', 'f4'))\n",
    "    \n",
    "    dtype_full.extend([\n",
    "        ('opacity', 'f4'),\n",
    "        ('scale_0', 'f4'), ('scale_1', 'f4'), ('scale_2', 'f4'),\n",
    "        ('rot_0', 'f4'), ('rot_1', 'f4'), ('rot_2', 'f4'), ('rot_3', 'f4'),\n",
    "    ])\n",
    "    \n",
    "    # Create structured array\n",
    "    elements = np.zeros(num_points, dtype=dtype_full)\n",
    "    \n",
    "    elements['x'] = xyz[:, 0]\n",
    "    elements['y'] = xyz[:, 1]\n",
    "    elements['z'] = xyz[:, 2]\n",
    "    elements['f_dc_0'] = features_dc[:, 0]\n",
    "    elements['f_dc_1'] = features_dc[:, 1]\n",
    "    elements['f_dc_2'] = features_dc[:, 2]\n",
    "    \n",
    "    for i in range(45):\n",
    "        elements[f'f_rest_{i}'] = features_rest[:, i]\n",
    "    \n",
    "    elements['opacity'] = opacities[:, 0]\n",
    "    elements['scale_0'] = scales[:, 0]\n",
    "    elements['scale_1'] = scales[:, 1]\n",
    "    elements['scale_2'] = scales[:, 2]\n",
    "    elements['rot_0'] = rotations[:, 0]\n",
    "    elements['rot_1'] = rotations[:, 1]\n",
    "    elements['rot_2'] = rotations[:, 2]\n",
    "    elements['rot_3'] = rotations[:, 3]\n",
    "    \n",
    "    # Write PLY\n",
    "    el = PlyElement.describe(elements, 'vertex')\n",
    "    PlyData([el]).write(output_path)\n",
    "    \n",
    "    print(f\"‚úÖ Saved Gaussian Splat PLY: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# Convert mesh to Gaussian format\n",
    "gs_ply_path = f\"{OUTPUT_DIR}/gaussian_splat.ply\"\n",
    "mesh_to_gaussian_ply(mesh, gs_ply_path, num_samples=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35f02a",
   "metadata": {},
   "source": [
    "## üîü Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50dc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"üì• Download your 3D models:\")\n",
    "print(\"\\n1. OBJ mesh (with vertex colors):\")\n",
    "files.download(obj_path)\n",
    "\n",
    "print(\"\\n2. GLB mesh (for web viewers):\")\n",
    "files.download(glb_path)\n",
    "\n",
    "print(\"\\n3. Gaussian Splat PLY (for gsplat optimization):\")\n",
    "files.download(gs_ply_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e328dff7",
   "metadata": {},
   "source": [
    "## üìä Render Preview Video (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d49e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsr.utils import save_video\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# Render 30 views around the object\n",
    "print(\"üé¨ Rendering preview video...\")\n",
    "with torch.no_grad():\n",
    "    render_images = model.render(\n",
    "        scene_codes, \n",
    "        n_views=30, \n",
    "        return_type=\"pil\"\n",
    "    )\n",
    "\n",
    "# Save video\n",
    "video_path = f\"{OUTPUT_DIR}/render.mp4\"\n",
    "save_video(render_images[0], video_path, fps=30)\n",
    "print(f\"‚úÖ Saved video: {video_path}\")\n",
    "\n",
    "# Display in notebook\n",
    "mp4 = open(video_path, 'rb').read()\n",
    "data_url = f\"data:video/mp4;base64,{b64encode(mp4).decode()}\"\n",
    "HTML(f'<video width=400 controls autoplay loop><source src=\"{data_url}\" type=\"video/mp4\"></video>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e74237",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Next Steps\n",
    "\n",
    "The `gaussian_splat.ply` file can now be used with:\n",
    "\n",
    "1. **SyncDreamer** - Generate 16 consistent multi-view images\n",
    "2. **gsplat optimization** - Refine the Gaussian Splats using multi-view supervision\n",
    "3. **SDXL Enhancement** - Enhance rendered views with diffusion\n",
    "4. **MVCRM Refinement** - Back-project enhancements into 3D\n",
    "\n",
    "Run the **Master Pipeline notebook** to execute the full Glimpse3D workflow!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
