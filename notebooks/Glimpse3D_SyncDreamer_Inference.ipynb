{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bfed986",
   "metadata": {},
   "source": [
    "# üé® Glimpse3D - SyncDreamer Inference\n",
    "\n",
    "**Multi-view image generation using your local Glimpse3D project files**\n",
    "\n",
    "## üñ•Ô∏è VS Code + Google Colab Setup\n",
    "\n",
    "This notebook is designed to run via the **VS Code Colab Extension** with your local project files.\n",
    "\n",
    "### Enable File Upload Feature:\n",
    "1. **Open VS Code Settings** (`Ctrl+,`)\n",
    "2. **Search for \"Colab\"**\n",
    "3. **Enable the experimental \"Uploading\" setting**\n",
    "4. **Reload VS Code** if prompted\n",
    "\n",
    "### Upload Project Files:\n",
    "Once enabled, right-click the **`ai_modules`** folder in the Explorer ‚Üí **\"Upload to Colab\"**\n",
    "\n",
    "> ‚ö†Ô∏è **Important:** Upload the entire `ai_modules` folder, NOT just `sync_dreamer`. This preserves the import path `from ai_modules.sync_dreamer import ...`\n",
    "\n",
    "---\n",
    "\n",
    "**Alternative:** The notebook will auto-clone from GitHub if local files aren't detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1aa34e",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check Environment & GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "043a2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Colab and GPU availability\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check for Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Colab: {IN_COLAB}\")\n",
    "\n",
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a32f92",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Setup Project Files on Colab\n",
    "\n",
    "**Option A: Use VS Code Colab Extension (Recommended)**\n",
    "1. Enable experimental features in VS Code Settings ‚Üí search \"Colab\" ‚Üí enable **Uploading**\n",
    "2. Right-click the **`ai_modules`** folder ‚Üí **\"Upload to Colab\"**\n",
    "3. Files will be uploaded to `/content/ai_modules/` on the Colab runtime\n",
    "\n",
    "> ‚ö†Ô∏è Upload `ai_modules` (the parent folder), NOT `sync_dreamer` alone!\n",
    "\n",
    "**Option B: Server Mounting (Advanced)**\n",
    "- Use Command Palette: `Colab: Mount Server To Workspace`\n",
    "- This lets you view/edit Colab files directly in VS Code!\n",
    "\n",
    "**Option C: Auto-Clone from GitHub (Fallback)**\n",
    "- If files aren't found, this cell will clone from the GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96127fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================\n",
    "# DIRECTORY STRUCTURE EXPLANATION:\n",
    "# ============================================================\n",
    "# When you upload \"ai_modules\" folder via VS Code Colab extension,\n",
    "# files go to: /content/ai_modules/sync_dreamer/\n",
    "#\n",
    "# When cloning from GitHub, files go to:\n",
    "# /content/Glimpse-3D/ai_modules/sync_dreamer/\n",
    "#\n",
    "# The import path is: from ai_modules.sync_dreamer import ...\n",
    "# So we need ai_modules/ to be in a directory that's on sys.path\n",
    "# ============================================================\n",
    "\n",
    "# Check possible locations for the ai_modules folder\n",
    "possible_paths = [\n",
    "    # VS Code \"Upload to Colab\" - uploads ai_modules to /content/\n",
    "    Path(\"/content/ai_modules/sync_dreamer\"),\n",
    "    # Git clone location\n",
    "    Path(\"/content/Glimpse-3D/ai_modules/sync_dreamer\"),\n",
    "]\n",
    "\n",
    "print(\"üîç Searching for ai_modules/sync_dreamer...\")\n",
    "FOUND_PATH = None\n",
    "PROJECT_ROOT = None\n",
    "\n",
    "for p in possible_paths:\n",
    "    print(f\"   Checking: {p}\", end=\"\")\n",
    "    if p.exists() and (p / \"inference.py\").exists():\n",
    "        FOUND_PATH = p\n",
    "        # Set PROJECT_ROOT to parent of ai_modules\n",
    "        PROJECT_ROOT = p.parent.parent  # sync_dreamer -> ai_modules -> project_root\n",
    "        print(\" ‚úÖ FOUND!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\" ‚ùå\")\n",
    "\n",
    "if FOUND_PATH is None:\n",
    "    print(\"\\n‚ö†Ô∏è ai_modules/sync_dreamer not found.\")\n",
    "    print(\"\\nüìã To upload from VS Code:\")\n",
    "    print(\"   1. Right-click 'ai_modules' folder (NOT sync_dreamer)\")\n",
    "    print(\"   2. Select 'Upload to Colab'\")\n",
    "    print(\"   3. Re-run this cell\")\n",
    "    print(\"\\n   Or clone from GitHub:\")\n",
    "    \n",
    "    user_choice = input(\"\\nClone from GitHub? (y/n): \").strip().lower()\n",
    "    if user_choice == 'y':\n",
    "        print(\"\\nüîÑ Cloning from GitHub repository...\")\n",
    "        !rm -rf /content/Glimpse-3D 2>/dev/null\n",
    "        !git clone https://github.com/varunaditya27/Glimpse-3D.git /content/Glimpse-3D\n",
    "        \n",
    "        FOUND_PATH = Path(\"/content/Glimpse-3D/ai_modules/sync_dreamer\")\n",
    "        PROJECT_ROOT = Path(\"/content/Glimpse-3D\")\n",
    "        \n",
    "        if FOUND_PATH.exists() and (FOUND_PATH / \"inference.py\").exists():\n",
    "            print(\"‚úÖ Successfully cloned!\")\n",
    "        else:\n",
    "            print(\"‚ùå Clone failed or ai_modules/sync_dreamer missing in repo.\")\n",
    "            FOUND_PATH = None\n",
    "    else:\n",
    "        print(\"\\n‚è∏Ô∏è Waiting for upload. Re-run this cell after uploading.\")\n",
    "\n",
    "# Set the SYNC_DREAMER_PATH variable for use in later cells\n",
    "if FOUND_PATH:\n",
    "    SYNC_DREAMER_PATH = FOUND_PATH\n",
    "    print(f\"\\n‚úÖ SYNC_DREAMER_PATH: {SYNC_DREAMER_PATH}\")\n",
    "    print(f\"üìÅ PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "    print(f\"\\nüìÇ Module contents:\")\n",
    "    for item in sorted(SYNC_DREAMER_PATH.iterdir()):\n",
    "        if item.is_dir():\n",
    "            print(f\"   üìÅ {item.name}/\")\n",
    "        else:\n",
    "            size_kb = item.stat().st_size / 1024\n",
    "            print(f\"   üìÑ {item.name} ({size_kb:.1f} KB)\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Cannot proceed without ai_modules/sync_dreamer. Please upload or clone first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d95aa",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf4b0cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Colab has PyTorch pre-installed - we just need the extras\n",
    "\n",
    "!pip install -q omegaconf pytorch-lightning==1.9.0 einops kornia\n",
    "!pip install -q transformers diffusers accelerate\n",
    "\n",
    "# Install CLIP (required for image encoding)\n",
    "!pip install -q git+https://github.com/openai/CLIP.git\n",
    "\n",
    "# Install taming-transformers (rom1504 fork - required for VAE)\n",
    "!pip install -q taming-transformers-rom1504\n",
    "\n",
    "# Install image processing libraries\n",
    "!pip install -q rembg[gpu] opencv-python-headless scikit-image imageio\n",
    "\n",
    "# Verify taming is installed correctly\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Verifying installations...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    from taming.modules.vqvae.quantize import VectorQuantizer2\n",
    "    print(\"‚úÖ taming-transformers installed correctly!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå taming import error: {e}\")\n",
    "\n",
    "try:\n",
    "    import clip\n",
    "    print(\"‚úÖ CLIP installed correctly!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå CLIP import error: {e}\")\n",
    "\n",
    "try:\n",
    "    from rembg import remove\n",
    "    print(\"‚úÖ rembg installed correctly!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå rembg import error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65096c",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Download Checkpoints (if needed)\n",
    "\n",
    "Downloads two checkpoint files (~6GB total):\n",
    "- `syncdreamer-pretrain.ckpt` (~5.2GB) - Main model weights\n",
    "- `ViT-L-14.pt` (~890MB) - CLIP image encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f34af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Checkpoint directory\n",
    "CKPT_DIR = SYNC_DREAMER_PATH / \"ckpt\"\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Required checkpoints\n",
    "CHECKPOINTS = {\n",
    "    \"syncdreamer-pretrain.ckpt\": {\n",
    "        \"url\": \"https://huggingface.co/camenduru/SyncDreamer/resolve/main/syncdreamer-pretrain.ckpt\",\n",
    "        \"size_gb\": 5.2\n",
    "    },\n",
    "    \"ViT-L-14.pt\": {\n",
    "        \"url\": \"https://huggingface.co/camenduru/SyncDreamer/resolve/main/ViT-L-14.pt\",\n",
    "        \"size_gb\": 0.89\n",
    "    }\n",
    "}\n",
    "\n",
    "# Install aria2 for faster downloads\n",
    "!apt -y install -qq aria2\n",
    "\n",
    "# Check and download each checkpoint\n",
    "for filename, info in CHECKPOINTS.items():\n",
    "    filepath = CKPT_DIR / filename\n",
    "    \n",
    "    if filepath.exists():\n",
    "        size_gb = filepath.stat().st_size / (1024**3)\n",
    "        if size_gb > info[\"size_gb\"] * 0.9:  # At least 90% of expected size\n",
    "            print(f\"‚úÖ {filename}: {size_gb:.2f} GB (already downloaded)\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {filename}: incomplete ({size_gb:.2f} GB), re-downloading...\")\n",
    "    \n",
    "    print(f\"üì• Downloading {filename} (~{info['size_gb']} GB)...\")\n",
    "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \\\n",
    "        \"{info['url']}\" \\\n",
    "        -d \"{CKPT_DIR}\" -o \"{filename}\"\n",
    "    \n",
    "    # Verify download\n",
    "    if filepath.exists():\n",
    "        size_gb = filepath.stat().st_size / (1024**3)\n",
    "        print(f\"‚úÖ {filename}: {size_gb:.2f} GB\")\n",
    "    else:\n",
    "        print(f\"‚ùå {filename}: Download failed!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"üìÅ Checkpoint directory: {CKPT_DIR}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c409fa",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Configure GPU Memory Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd37ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Set environment variables for memory optimization\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "\n",
    "# Enable memory-efficient settings\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "def print_gpu_memory():\n",
    "    \"\"\"Print current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"GPU Memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved, {total:.1f}GB total\")\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory cache\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"üßπ GPU memory cache cleared\")\n",
    "    print_gpu_memory()\n",
    "\n",
    "# Initial memory check\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e29eb1e",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Load Glimpse3D SyncDreamer Module\n",
    "\n",
    "This loads the `SyncDreamerService` from the Glimpse3D `ai_modules/sync_dreamer/` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8a4d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add PROJECT_ROOT to sys.path so Python can find ai_modules\n",
    "# PROJECT_ROOT is the parent of ai_modules (e.g., /content or /content/Glimpse-3D)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "    print(f\"‚úÖ Added to sys.path: {PROJECT_ROOT}\")\n",
    "\n",
    "# Also add SYNC_DREAMER_PATH for ldm submodule imports\n",
    "if str(SYNC_DREAMER_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(SYNC_DREAMER_PATH))\n",
    "    print(f\"‚úÖ Added to sys.path: {SYNC_DREAMER_PATH}\")\n",
    "\n",
    "print(f\"\\nüìÅ PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "print(f\"üìÅ SYNC_DREAMER_PATH: {SYNC_DREAMER_PATH}\")\n",
    "\n",
    "# Import the Glimpse3D SyncDreamer module\n",
    "print(\"\\nüîÑ Importing modules...\")\n",
    "try:\n",
    "    from ai_modules.sync_dreamer import SyncDreamerService, generate_multiview\n",
    "    from ai_modules.sync_dreamer.utils_syncdreamer import segment_foreground, preprocess_for_syncdreamer\n",
    "    print(\"‚úÖ Successfully imported from ai_modules.sync_dreamer!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"\\nüîÑ Trying fallback direct import...\")\n",
    "    try:\n",
    "        from inference import SyncDreamerService, generate_multiview\n",
    "        from utils_syncdreamer import segment_foreground, preprocess_for_syncdreamer\n",
    "        print(\"‚úÖ Successfully imported via direct path!\")\n",
    "    except ImportError as e2:\n",
    "        print(f\"‚ùå Fallback also failed: {e2}\")\n",
    "        print(\"\\n‚ö†Ô∏è Make sure you uploaded 'ai_modules' folder, not just 'sync_dreamer'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a65b8b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SyncDreamer service\n",
    "print(\"üîÑ Initializing SyncDreamer service...\")\n",
    "\n",
    "# Create service with paths to our checkpoints\n",
    "service = SyncDreamerService(\n",
    "    config_path=str(SYNC_DREAMER_PATH / \"configs\" / \"syncdreamer.yaml\"),\n",
    "    checkpoint_path=str(SYNC_DREAMER_PATH / \"ckpt\" / \"syncdreamer-pretrain.ckpt\"),\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "print(\"\\nüîÑ Loading model weights (this may take a minute)...\")\n",
    "service.load_model()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ SyncDreamer model loaded and ready!\")\n",
    "print(\"=\"*50)\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0036ca50",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Prepare Test Image\n",
    "\n",
    "You can:\n",
    "1. Use a sample image from your project's assets\n",
    "2. Upload your own image\n",
    "3. Download a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e77c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# Output directory for results\n",
    "OUTPUT_DIR = Path(\"/content/output\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =====================================================\n",
    "# OPTION 1: Download a test image\n",
    "# =====================================================\n",
    "TEST_IMAGE_URL = \"https://huggingface.co/spaces/One-2-3-45/One-2-3-45/resolve/main/demo_examples/01_astronaut.png\"\n",
    "TEST_IMAGE_PATH = Path(\"/content/test_input.png\")\n",
    "\n",
    "!wget -q \"{TEST_IMAGE_URL}\" -O \"{TEST_IMAGE_PATH}\"\n",
    "print(f\"üì• Downloaded test image to: {TEST_IMAGE_PATH}\")\n",
    "\n",
    "# =====================================================\n",
    "# OPTION 2: Upload your own image (uncomment to use)\n",
    "# =====================================================\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# TEST_IMAGE_PATH = Path(list(uploaded.keys())[0])\n",
    "# print(f\"üì§ Uploaded: {TEST_IMAGE_PATH}\")\n",
    "\n",
    "# =====================================================\n",
    "# OPTION 3: Use from project assets (uncomment to use)\n",
    "# =====================================================\n",
    "# TEST_IMAGE_PATH = PROJECT_ROOT / \"assets\" / \"sample_inputs\" / \"your_image.png\"\n",
    "\n",
    "# Display the test image\n",
    "print(f\"\\nüì∑ Using test image: {TEST_IMAGE_PATH}\")\n",
    "img = Image.open(TEST_IMAGE_PATH)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Input Image ({img.size[0]}x{img.size[1]}, {img.mode})\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image size: {img.size}\")\n",
    "print(f\"Image mode: {img.mode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b995b",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Preprocess Image (Background Removal)\n",
    "\n",
    "SyncDreamer works best with images that have transparent backgrounds. We'll use `rembg` to remove the background if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d5ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load image\n",
    "input_img = Image.open(TEST_IMAGE_PATH)\n",
    "\n",
    "# Check if image already has transparency\n",
    "needs_segmentation = True\n",
    "if input_img.mode == 'RGBA':\n",
    "    alpha = np.array(input_img)[:, :, 3]\n",
    "    if np.any(alpha < 255):\n",
    "        print(\"‚úÖ Image already has transparent background\")\n",
    "        needs_segmentation = False\n",
    "\n",
    "# Remove background if needed\n",
    "if needs_segmentation:\n",
    "    print(\"üîÑ Removing background with rembg...\")\n",
    "    processed_img = segment_foreground(input_img, method=\"rembg\")\n",
    "    print(\"‚úÖ Background removed!\")\n",
    "else:\n",
    "    processed_img = input_img\n",
    "\n",
    "# Save processed image\n",
    "PROCESSED_IMAGE_PATH = OUTPUT_DIR / \"processed_input.png\"\n",
    "processed_img.save(PROCESSED_IMAGE_PATH)\n",
    "\n",
    "# Display comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].imshow(input_img)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(processed_img)\n",
    "axes[1].set_title(\"Processed (Background Removed)\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìÅ Processed image saved to: {PROCESSED_IMAGE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff0b38e",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Run Multi-View Generation\n",
    "\n",
    "**Key Parameters:**\n",
    "- `elevation`: Input view elevation angle (0-40¬∞, typically 30¬∞)\n",
    "- `crop_size`: Size to crop foreground to (default 200)\n",
    "- `cfg_scale`: Classifier-free guidance scale (default 2.0)\n",
    "- `batch_view_num`: Views per batch (4 for T4, 8 for A100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# ============================================\n",
    "# INFERENCE PARAMETERS\n",
    "# ============================================\n",
    "ELEVATION = 30.0        # Input view elevation (degrees)\n",
    "CROP_SIZE = 200         # Foreground crop size (-1 to disable)\n",
    "CFG_SCALE = 2.0         # Classifier-free guidance scale\n",
    "BATCH_VIEW_NUM = 4      # 4 for T4 (15GB), 8 for A100\n",
    "SAMPLE_NUM = 1          # Number of sample sets\n",
    "SAMPLE_STEPS = 50       # DDIM sampling steps\n",
    "SEED = 42               # Random seed\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"üöÄ Running Glimpse3D SyncDreamer Inference\")\n",
    "print(\"=\"*50)\n",
    "print(f\"üì∑ Input: {PROCESSED_IMAGE_PATH}\")\n",
    "print(f\"üìê Elevation: {ELEVATION}¬∞\")\n",
    "print(f\"üéØ CFG Scale: {CFG_SCALE}\")\n",
    "print(f\"üì¶ Batch View Num: {BATCH_VIEW_NUM}\")\n",
    "print(f\"üî¢ Sample Steps: {SAMPLE_STEPS}\")\n",
    "print(f\"üé≤ Seed: {SEED}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print_gpu_memory()\n",
    "\n",
    "# Run inference using Glimpse3D service\n",
    "print(\"\\n‚è≥ Generating 16 multi-view images...\")\n",
    "start_time = time.time()\n",
    "\n",
    "generated_views = service.generate(\n",
    "    image=str(PROCESSED_IMAGE_PATH),\n",
    "    elevation=ELEVATION,\n",
    "    crop_size=CROP_SIZE,\n",
    "    cfg_scale=CFG_SCALE,\n",
    "    sample_num=SAMPLE_NUM,\n",
    "    batch_view_num=BATCH_VIEW_NUM,\n",
    "    sample_steps=SAMPLE_STEPS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Generation complete in {elapsed_time:.1f} seconds!\")\n",
    "print(f\"üìä Generated {len(generated_views)} views\")\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae586a5",
   "metadata": {},
   "source": [
    "## üîü Visualize Generated Views\n",
    "\n",
    "The 16 views are arranged as:\n",
    "- **Row 1-2**: Elevation 30¬∞ (views 0-7)\n",
    "- **Row 3-4**: Elevation -20¬∞ (views 8-15)\n",
    "- **Columns**: Azimuths 0¬∞, 45¬∞, 90¬∞, 135¬∞, 180¬∞, 225¬∞, 270¬∞, 315¬∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get camera configuration from service\n",
    "elevations = service.ELEVATIONS\n",
    "azimuths = service.AZIMUTHS\n",
    "\n",
    "# Create 4x4 grid visualization\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "\n",
    "for i in range(16):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    axes[row, col].imshow(generated_views[i])\n",
    "    axes[row, col].set_title(f\"View {i}: E={elevations[i]}¬∞ A={azimuths[i]}¬∞\", fontsize=10)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle(\"Glimpse3D SyncDreamer - Generated Multi-View Images\", fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save grid\n",
    "grid_path = OUTPUT_DIR / \"multiview_grid.png\"\n",
    "plt.savefig(grid_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Grid saved to {grid_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d065b",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Save Output Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865933d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "# Save individual views\n",
    "print(\"üíæ Saving individual views...\")\n",
    "saved_paths = []\n",
    "\n",
    "for i, view in enumerate(generated_views[:16]):\n",
    "    filename = f\"view_{i:02d}_elev{elevations[i]}_azim{azimuths[i]}.png\"\n",
    "    path = OUTPUT_DIR / filename\n",
    "    view.save(path)\n",
    "    saved_paths.append(path)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(saved_paths)} individual views to {OUTPUT_DIR}/\")\n",
    "\n",
    "# Save concatenated strip\n",
    "concat_images = [np.array(v) for v in generated_views[:16]]\n",
    "concat_strip = np.concatenate(concat_images, axis=1)\n",
    "strip_path = OUTPUT_DIR / \"concat_strip.png\"\n",
    "Image.fromarray(concat_strip).save(strip_path)\n",
    "print(f\"‚úÖ Saved concatenated strip to {strip_path}\")\n",
    "\n",
    "# Create turntable GIF\n",
    "print(\"üé¨ Creating turntable animation...\")\n",
    "turntable_views = [np.array(generated_views[i]) for i in range(8)]  # First 8 views (30¬∞ elevation)\n",
    "turntable_loop = turntable_views + turntable_views[::-1][1:-1]  # Forward + reverse for smooth loop\n",
    "\n",
    "gif_path = OUTPUT_DIR / \"turntable.gif\"\n",
    "imageio.mimsave(gif_path, turntable_loop, fps=4, loop=0)\n",
    "print(f\"‚úÖ Saved turntable GIF to {gif_path}\")\n",
    "\n",
    "# Display GIF\n",
    "from IPython.display import Image as IPImage, display\n",
    "display(IPImage(filename=str(gif_path)))\n",
    "\n",
    "# List all output files\n",
    "print(f\"\\nüìÅ Output files in {OUTPUT_DIR}:\")\n",
    "for f in sorted(OUTPUT_DIR.iterdir()):\n",
    "    size_kb = f.stat().st_size / 1024\n",
    "    print(f\"  - {f.name} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde25f39",
   "metadata": {},
   "source": [
    "## üì• Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d132b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# Create ZIP archive\n",
    "zip_path = Path(\"/content/glimpse3d_syncdreamer_output\")\n",
    "shutil.make_archive(str(zip_path), 'zip', OUTPUT_DIR)\n",
    "print(f\"üì¶ Created {zip_path}.zip\")\n",
    "\n",
    "# Download\n",
    "files.download(f\"{zip_path}.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e079013",
   "metadata": {},
   "source": [
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2711ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unload model to free GPU memory\n",
    "service.unload_model()\n",
    "\n",
    "# Or use the cleanup function\n",
    "# from ai_modules.sync_dreamer import cleanup\n",
    "# cleanup()\n",
    "\n",
    "clear_gpu_memory()\n",
    "print(\"‚úÖ Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e4d0a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Quick Reference: Using Glimpse3D SyncDreamer Module\n",
    "\n",
    "### Method 1: Quick Function\n",
    "```python\n",
    "from ai_modules.sync_dreamer import generate_multiview\n",
    "\n",
    "# Generate and save in one call\n",
    "output_paths = generate_multiview(\n",
    "    image_path=\"input.png\",\n",
    "    output_dir=\"outputs/\",\n",
    "    elevation=30.0,\n",
    "    seed=42\n",
    ")\n",
    "```\n",
    "\n",
    "### Method 2: Service Class (More Control)\n",
    "```python\n",
    "from ai_modules.sync_dreamer import SyncDreamerService\n",
    "\n",
    "# Initialize and load\n",
    "service = SyncDreamerService()\n",
    "service.load_model()\n",
    "\n",
    "# Generate images (returns PIL Images)\n",
    "views = service.generate(\n",
    "    image=\"input.png\",\n",
    "    elevation=30.0,\n",
    "    batch_view_num=4  # Use 4 for T4, 8 for A100\n",
    ")\n",
    "\n",
    "# Or generate and save\n",
    "paths = service.generate_and_save(\n",
    "    image=\"input.png\",\n",
    "    output_dir=\"outputs/\",\n",
    "    save_grid=True\n",
    ")\n",
    "\n",
    "# Cleanup\n",
    "service.unload_model()\n",
    "```\n",
    "\n",
    "### Method 3: Preprocessing Utilities\n",
    "```python\n",
    "from ai_modules.sync_dreamer.utils_syncdreamer import (\n",
    "    segment_foreground,\n",
    "    preprocess_for_syncdreamer\n",
    ")\n",
    "\n",
    "# Remove background\n",
    "rgba_image = segment_foreground(image, method=\"rembg\")\n",
    "\n",
    "# Full preprocessing\n",
    "processed = preprocess_for_syncdreamer(image, crop_size=200)\n",
    "```\n",
    "\n",
    "### Output Camera Configuration\n",
    "SyncDreamer generates 16 views at fixed camera positions:\n",
    "- Views 0-7: Elevation 30¬∞, Azimuth 0¬∞-315¬∞ (45¬∞ steps)\n",
    "- Views 8-15: Elevation -20¬∞, Azimuth 0¬∞-315¬∞ (45¬∞ steps)\n",
    "\n",
    "### Tips\n",
    "- **Elevation**: Front-facing photos ‚Üí 30¬∞, Top-down ‚Üí 60-80¬∞\n",
    "- **VRAM**: Use `batch_view_num=4` for T4 (15GB), `batch_view_num=8` for A100\n",
    "- **Quality**: Try different `crop_size` values (150-200) for best results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
