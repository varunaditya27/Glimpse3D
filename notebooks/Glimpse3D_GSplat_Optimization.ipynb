{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958a1677",
   "metadata": {},
   "source": [
    "# üîÆ Glimpse3D - gsplat Gaussian Optimization\n",
    "\n",
    "**Optimize Gaussian Splats using multi-view images**\n",
    "\n",
    "This notebook refines the initial Gaussian point cloud using multi-view supervision.\n",
    "\n",
    "## Pipeline Role\n",
    "```\n",
    "TripoSR ‚Üí [This Notebook] ‚Üí Optimized Splats ‚Üí Rendering ‚Üí Enhancement\n",
    "```\n",
    "\n",
    "## Requirements\n",
    "- Google Colab with **T4 GPU** (15GB VRAM)\n",
    "- Input: Gaussian PLY from TripoSR + Multi-view images from SyncDreamer\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff65d4",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check GPU & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe1687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Colab: {IN_COLAB}\")\n",
    "\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e073a01b",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Install gsplat & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install gsplat (CUDA-accelerated Gaussian Splatting)\n",
    "!pip install gsplat --quiet\n",
    "\n",
    "# Additional dependencies\n",
    "!pip install plyfile numpy pillow matplotlib tqdm --quiet\n",
    "!pip install torch torchvision --quiet\n",
    "\n",
    "print(\"‚úÖ gsplat installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify gsplat installation\n",
    "import gsplat\n",
    "print(f\"‚úÖ gsplat version: {gsplat.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3129633",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Load Gaussian PLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Create working directory\n",
    "WORK_DIR = \"/content/gsplat_work\"\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "# Upload Gaussian PLY\n",
    "print(\"üì§ Upload gaussian_splat.ply from TripoSR:\")\n",
    "uploaded = files.upload()\n",
    "PLY_PATH = os.path.join(WORK_DIR, list(uploaded.keys())[0])\n",
    "with open(PLY_PATH, 'wb') as f:\n",
    "    f.write(list(uploaded.values())[0])\n",
    "print(f\"‚úÖ Loaded: {PLY_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "import torch\n",
    "\n",
    "def load_gaussian_ply(path):\n",
    "    \"\"\"Load Gaussian Splat PLY file into tensors.\"\"\"\n",
    "    plydata = PlyData.read(path)\n",
    "    vertex = plydata['vertex']\n",
    "    \n",
    "    # Positions\n",
    "    xyz = np.stack([vertex['x'], vertex['y'], vertex['z']], axis=-1)\n",
    "    \n",
    "    # SH DC coefficients\n",
    "    f_dc = np.stack([vertex['f_dc_0'], vertex['f_dc_1'], vertex['f_dc_2']], axis=-1)\n",
    "    \n",
    "    # SH rest coefficients\n",
    "    f_rest_names = [f'f_rest_{i}' for i in range(45)]\n",
    "    f_rest = np.stack([vertex[name] for name in f_rest_names if name in vertex.data.dtype.names], axis=-1)\n",
    "    \n",
    "    # Opacity\n",
    "    opacity = vertex['opacity']\n",
    "    \n",
    "    # Scales\n",
    "    scales = np.stack([vertex['scale_0'], vertex['scale_1'], vertex['scale_2']], axis=-1)\n",
    "    \n",
    "    # Rotations (quaternion)\n",
    "    rotations = np.stack([vertex['rot_0'], vertex['rot_1'], vertex['rot_2'], vertex['rot_3']], axis=-1)\n",
    "    \n",
    "    return {\n",
    "        'xyz': torch.tensor(xyz, dtype=torch.float32),\n",
    "        'f_dc': torch.tensor(f_dc, dtype=torch.float32),\n",
    "        'f_rest': torch.tensor(f_rest, dtype=torch.float32),\n",
    "        'opacity': torch.tensor(opacity, dtype=torch.float32),\n",
    "        'scales': torch.tensor(scales, dtype=torch.float32),\n",
    "        'rotations': torch.tensor(rotations, dtype=torch.float32),\n",
    "    }\n",
    "\n",
    "# Load Gaussians\n",
    "gaussians = load_gaussian_ply(PLY_PATH)\n",
    "print(f\"‚úÖ Loaded {len(gaussians['xyz']):,} Gaussians\")\n",
    "print(f\"   Bounds: {gaussians['xyz'].min(0).values.numpy()} to {gaussians['xyz'].max(0).values.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fef297",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Upload Multi-View Images (Optional)\n",
    "\n",
    "If you have multi-view images from SyncDreamer, upload them for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MULTIVIEW_DIR = os.path.join(WORK_DIR, \"multiview\")\n",
    "os.makedirs(MULTIVIEW_DIR, exist_ok=True)\n",
    "\n",
    "use_multiview = input(\"Do you have multi-view images? (y/n): \").lower() == 'y'\n",
    "\n",
    "if use_multiview:\n",
    "    print(\"üì§ Upload multi-view images (ZIP file or individual PNGs):\")\n",
    "    uploaded_mv = files.upload()\n",
    "    \n",
    "    for fname, content in uploaded_mv.items():\n",
    "        if fname.endswith('.zip'):\n",
    "            # Extract ZIP\n",
    "            zip_path = os.path.join(WORK_DIR, fname)\n",
    "            with open(zip_path, 'wb') as f:\n",
    "                f.write(content)\n",
    "            with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "                z.extractall(MULTIVIEW_DIR)\n",
    "            print(f\"‚úÖ Extracted {fname}\")\n",
    "        else:\n",
    "            # Save individual image\n",
    "            img_path = os.path.join(MULTIVIEW_DIR, fname)\n",
    "            with open(img_path, 'wb') as f:\n",
    "                f.write(content)\n",
    "    \n",
    "    # List images\n",
    "    image_files = sorted([f for f in os.listdir(MULTIVIEW_DIR) if f.endswith(('.png', '.jpg'))])\n",
    "    print(f\"\\n‚úÖ Found {len(image_files)} multi-view images\")\n",
    "else:\n",
    "    image_files = []\n",
    "    print(\"‚è≠Ô∏è Skipping multi-view optimization (will use synthetic views)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ef694",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Setup Camera System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb97386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def generate_camera_poses(n_views=16, radius=2.0, elevation=30.0):\n",
    "    \"\"\"\n",
    "    Generate camera poses around the object.\n",
    "    Returns world-to-camera matrices (4x4).\n",
    "    \"\"\"\n",
    "    poses = []\n",
    "    elevation_rad = math.radians(elevation)\n",
    "    \n",
    "    for i in range(n_views):\n",
    "        azimuth = 2 * math.pi * i / n_views\n",
    "        \n",
    "        # Camera position in world coordinates\n",
    "        x = radius * math.cos(elevation_rad) * math.cos(azimuth)\n",
    "        y = radius * math.cos(elevation_rad) * math.sin(azimuth)\n",
    "        z = radius * math.sin(elevation_rad)\n",
    "        \n",
    "        # Look at origin\n",
    "        cam_pos = np.array([x, y, z])\n",
    "        look_at = np.array([0, 0, 0])\n",
    "        up = np.array([0, 0, 1])\n",
    "        \n",
    "        # Camera basis vectors\n",
    "        forward = look_at - cam_pos\n",
    "        forward = forward / np.linalg.norm(forward)\n",
    "        \n",
    "        right = np.cross(forward, up)\n",
    "        right = right / np.linalg.norm(right)\n",
    "        \n",
    "        up_new = np.cross(right, forward)\n",
    "        \n",
    "        # World-to-camera matrix\n",
    "        w2c = np.eye(4)\n",
    "        w2c[:3, 0] = right\n",
    "        w2c[:3, 1] = up_new\n",
    "        w2c[:3, 2] = -forward\n",
    "        w2c[:3, 3] = -w2c[:3, :3] @ cam_pos\n",
    "        \n",
    "        poses.append(w2c)\n",
    "    \n",
    "    return np.stack(poses)\n",
    "\n",
    "def get_projection_matrix(fov_deg=60, aspect=1.0, near=0.1, far=100.0):\n",
    "    \"\"\"Create OpenGL-style projection matrix.\"\"\"\n",
    "    fov_rad = math.radians(fov_deg)\n",
    "    f = 1.0 / math.tan(fov_rad / 2)\n",
    "    \n",
    "    proj = np.zeros((4, 4))\n",
    "    proj[0, 0] = f / aspect\n",
    "    proj[1, 1] = f\n",
    "    proj[2, 2] = (far + near) / (near - far)\n",
    "    proj[2, 3] = 2 * far * near / (near - far)\n",
    "    proj[3, 2] = -1\n",
    "    \n",
    "    return proj\n",
    "\n",
    "# Generate camera system\n",
    "N_VIEWS = 16\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "camera_poses = generate_camera_poses(n_views=N_VIEWS, radius=2.0, elevation=30.0)\n",
    "projection = get_projection_matrix(fov_deg=60, aspect=1.0)\n",
    "\n",
    "print(f\"‚úÖ Generated {N_VIEWS} camera poses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532e7b6",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Define Gaussian Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab135c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class GaussianModel(nn.Module):\n",
    "    \"\"\"Differentiable Gaussian Splat Model.\"\"\"\n",
    "    \n",
    "    def __init__(self, gaussians):\n",
    "        super().__init__()\n",
    "        n_points = len(gaussians['xyz'])\n",
    "        \n",
    "        # Learnable parameters\n",
    "        self.xyz = nn.Parameter(gaussians['xyz'].clone())\n",
    "        self.f_dc = nn.Parameter(gaussians['f_dc'].clone())\n",
    "        self.f_rest = nn.Parameter(gaussians['f_rest'].clone())\n",
    "        self.opacity_raw = nn.Parameter(gaussians['opacity'].clone())\n",
    "        self.scales_raw = nn.Parameter(gaussians['scales'].clone())\n",
    "        self.rotations = nn.Parameter(gaussians['rotations'].clone())\n",
    "        \n",
    "    @property\n",
    "    def opacity(self):\n",
    "        return torch.sigmoid(self.opacity_raw)\n",
    "    \n",
    "    @property\n",
    "    def scales(self):\n",
    "        return torch.exp(self.scales_raw)\n",
    "    \n",
    "    def get_colors(self):\n",
    "        \"\"\"Get RGB colors from SH DC coefficients.\"\"\"\n",
    "        C0 = 0.28209479177387814\n",
    "        return 0.5 + C0 * self.f_dc\n",
    "    \n",
    "    def forward(self):\n",
    "        return {\n",
    "            'xyz': self.xyz,\n",
    "            'colors': self.get_colors(),\n",
    "            'opacity': self.opacity,\n",
    "            'scales': self.scales,\n",
    "            'rotations': self.rotations / (self.rotations.norm(dim=-1, keepdim=True) + 1e-8),\n",
    "        }\n",
    "\n",
    "# Initialize model\n",
    "model = GaussianModel(gaussians).to(device)\n",
    "print(f\"‚úÖ Model initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a3520",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Render Function using gsplat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsplat import rasterization\n",
    "\n",
    "def render_gaussians(model, w2c, proj, image_size=512):\n",
    "    \"\"\"\n",
    "    Render Gaussian splats from a given camera pose.\n",
    "    \n",
    "    Args:\n",
    "        model: GaussianModel instance\n",
    "        w2c: World-to-camera matrix (4x4)\n",
    "        proj: Projection matrix (4x4)\n",
    "        image_size: Output image resolution\n",
    "    \n",
    "    Returns:\n",
    "        Rendered RGB image (H, W, 3)\n",
    "    \"\"\"\n",
    "    params = model()\n",
    "    \n",
    "    # Convert to tensors\n",
    "    viewmat = torch.tensor(w2c, dtype=torch.float32, device=device)\n",
    "    K = torch.tensor([\n",
    "        [proj[0, 0] * image_size / 2, 0, image_size / 2],\n",
    "        [0, proj[1, 1] * image_size / 2, image_size / 2],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Render using gsplat\n",
    "    render_colors, render_alphas, meta = rasterization(\n",
    "        means=params['xyz'],\n",
    "        quats=params['rotations'],\n",
    "        scales=params['scales'],\n",
    "        opacities=params['opacity'],\n",
    "        colors=params['colors'],\n",
    "        viewmats=viewmat.unsqueeze(0),\n",
    "        Ks=K.unsqueeze(0),\n",
    "        width=image_size,\n",
    "        height=image_size,\n",
    "        packed=False,\n",
    "        render_mode=\"RGB\",\n",
    "    )\n",
    "    \n",
    "    return render_colors[0], render_alphas[0]\n",
    "\n",
    "# Test render\n",
    "with torch.no_grad():\n",
    "    test_image, test_alpha = render_gaussians(model, camera_poses[0], projection, IMAGE_SIZE)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image.cpu().numpy().clip(0, 1))\n",
    "plt.title(\"RGB Render\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_alpha.cpu().numpy(), cmap='gray')\n",
    "plt.title(\"Alpha\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af98ef3",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Optimization Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimization settings\n",
    "NUM_ITERATIONS = 1000\n",
    "LR_XYZ = 1e-4\n",
    "LR_COLOR = 1e-3\n",
    "LR_OPACITY = 0.05\n",
    "LR_SCALE = 5e-3\n",
    "LR_ROTATION = 1e-3\n",
    "\n",
    "# Setup optimizer with per-parameter learning rates\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.xyz, 'lr': LR_XYZ},\n",
    "    {'params': model.f_dc, 'lr': LR_COLOR},\n",
    "    {'params': model.f_rest, 'lr': LR_COLOR / 20},\n",
    "    {'params': model.opacity_raw, 'lr': LR_OPACITY},\n",
    "    {'params': model.scales_raw, 'lr': LR_SCALE},\n",
    "    {'params': model.rotations, 'lr': LR_ROTATION},\n",
    "])\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.995)\n",
    "\n",
    "# Load target images if available\n",
    "if use_multiview and len(image_files) > 0:\n",
    "    target_images = []\n",
    "    for f in image_files[:N_VIEWS]:\n",
    "        img = Image.open(os.path.join(MULTIVIEW_DIR, f)).convert('RGB')\n",
    "        img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "        img_tensor = torch.tensor(np.array(img) / 255.0, dtype=torch.float32, device=device)\n",
    "        target_images.append(img_tensor)\n",
    "    print(f\"‚úÖ Loaded {len(target_images)} target images for supervision\")\n",
    "else:\n",
    "    target_images = None\n",
    "    print(\"‚ö†Ô∏è No target images - using self-supervision only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb42b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "losses = []\n",
    "\n",
    "print(\"üöÄ Starting optimization...\")\n",
    "pbar = tqdm(range(NUM_ITERATIONS))\n",
    "\n",
    "for iteration in pbar:\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Sample random view\n",
    "    view_idx = np.random.randint(0, N_VIEWS)\n",
    "    w2c = camera_poses[view_idx]\n",
    "    \n",
    "    # Render\n",
    "    rendered, alpha = render_gaussians(model, w2c, projection, IMAGE_SIZE)\n",
    "    \n",
    "    # Compute loss\n",
    "    if target_images is not None and view_idx < len(target_images):\n",
    "        # Photometric loss with target\n",
    "        target = target_images[view_idx]\n",
    "        loss = F.mse_loss(rendered, target)\n",
    "    else:\n",
    "        # Self-supervision: encourage opacity and smooth colors\n",
    "        loss = -alpha.mean() * 0.1  # Encourage visibility\n",
    "        \n",
    "        # Regularization\n",
    "        loss += (model.scales_raw.abs().mean() - 1.0).abs() * 0.01  # Scale regularization\n",
    "    \n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if iteration % 100 == 0:\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "print(f\"\\n‚úÖ Optimization complete! Final loss: {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Optimization Progress')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c11aa0",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Render All Views & Create Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f459d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "# Render all views\n",
    "print(\"üé¨ Rendering optimized views...\")\n",
    "rendered_views = []\n",
    "\n",
    "# Generate more views for smooth video\n",
    "video_poses = generate_camera_poses(n_views=60, radius=2.0, elevation=30.0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for pose in tqdm(video_poses):\n",
    "        img, _ = render_gaussians(model, pose, projection, IMAGE_SIZE)\n",
    "        img_np = (img.cpu().numpy().clip(0, 1) * 255).astype(np.uint8)\n",
    "        rendered_views.append(img_np)\n",
    "\n",
    "# Save video\n",
    "video_path = os.path.join(WORK_DIR, \"optimized_render.mp4\")\n",
    "imageio.mimsave(video_path, rendered_views, fps=30)\n",
    "print(f\"‚úÖ Saved video: {video_path}\")\n",
    "\n",
    "# Display sample frames\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = i * len(rendered_views) // 8\n",
    "    ax.imshow(rendered_views[idx])\n",
    "    ax.set_title(f\"View {idx}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8513818",
   "metadata": {},
   "source": [
    "## üîü Export Optimized PLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gaussian_ply(model, output_path):\n",
    "    \"\"\"Save optimized Gaussians to PLY file.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        params = model()\n",
    "        \n",
    "        xyz = params['xyz'].cpu().numpy()\n",
    "        colors = model.f_dc.cpu().numpy()\n",
    "        f_rest = model.f_rest.cpu().numpy()\n",
    "        opacity = model.opacity_raw.cpu().numpy()\n",
    "        scales = model.scales_raw.cpu().numpy()\n",
    "        rotations = params['rotations'].cpu().numpy()\n",
    "        \n",
    "    num_points = len(xyz)\n",
    "    \n",
    "    # Build dtype\n",
    "    dtype_full = [\n",
    "        ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),\n",
    "        ('f_dc_0', 'f4'), ('f_dc_1', 'f4'), ('f_dc_2', 'f4'),\n",
    "    ]\n",
    "    for i in range(f_rest.shape[1]):\n",
    "        dtype_full.append((f'f_rest_{i}', 'f4'))\n",
    "    dtype_full.extend([\n",
    "        ('opacity', 'f4'),\n",
    "        ('scale_0', 'f4'), ('scale_1', 'f4'), ('scale_2', 'f4'),\n",
    "        ('rot_0', 'f4'), ('rot_1', 'f4'), ('rot_2', 'f4'), ('rot_3', 'f4'),\n",
    "    ])\n",
    "    \n",
    "    # Create array\n",
    "    elements = np.zeros(num_points, dtype=dtype_full)\n",
    "    elements['x'] = xyz[:, 0]\n",
    "    elements['y'] = xyz[:, 1]\n",
    "    elements['z'] = xyz[:, 2]\n",
    "    elements['f_dc_0'] = colors[:, 0]\n",
    "    elements['f_dc_1'] = colors[:, 1]\n",
    "    elements['f_dc_2'] = colors[:, 2]\n",
    "    for i in range(f_rest.shape[1]):\n",
    "        elements[f'f_rest_{i}'] = f_rest[:, i]\n",
    "    elements['opacity'] = opacity\n",
    "    elements['scale_0'] = scales[:, 0]\n",
    "    elements['scale_1'] = scales[:, 1]\n",
    "    elements['scale_2'] = scales[:, 2]\n",
    "    elements['rot_0'] = rotations[:, 0]\n",
    "    elements['rot_1'] = rotations[:, 1]\n",
    "    elements['rot_2'] = rotations[:, 2]\n",
    "    elements['rot_3'] = rotations[:, 3]\n",
    "    \n",
    "    from plyfile import PlyElement, PlyData\n",
    "    el = PlyElement.describe(elements, 'vertex')\n",
    "    PlyData([el]).write(output_path)\n",
    "    print(f\"‚úÖ Saved: {output_path}\")\n",
    "\n",
    "# Save optimized PLY\n",
    "optimized_ply_path = os.path.join(WORK_DIR, \"optimized_gaussian.ply\")\n",
    "save_gaussian_ply(model, optimized_ply_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6668c80",
   "metadata": {},
   "source": [
    "## üì• Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45408590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"üì• Downloading results...\")\n",
    "\n",
    "# Download optimized PLY\n",
    "files.download(optimized_ply_path)\n",
    "\n",
    "# Download video\n",
    "files.download(video_path)\n",
    "\n",
    "print(\"\\n‚úÖ Downloads complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdcb6c7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Next Steps\n",
    "\n",
    "The optimized Gaussian Splats can now be used for:\n",
    "\n",
    "1. **Rendering high-quality novel views**\n",
    "2. **SDXL Enhancement** - Enhance specific views with diffusion\n",
    "3. **MVCRM Refinement** - Back-project enhancements into the 3D representation\n",
    "\n",
    "Continue with the **Master Pipeline notebook** for the full Glimpse3D workflow!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
