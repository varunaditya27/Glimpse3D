{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d85cf6",
   "metadata": {},
   "source": [
    "# üé® Glimpse3D Diffusion Enhancement Module\n",
    "\n",
    "This notebook tests the `ai_modules/diffusion/` module for enhancing 3D rendered views using **SDXL Lightning + ControlNet Depth**.\n",
    "\n",
    "## üñ•Ô∏è VS Code Colab Extension Setup\n",
    "\n",
    "**You're using this notebook with the VS Code Colab Extension!** Here's what you need to know:\n",
    "\n",
    "### How It Works\n",
    "1. **Kernel runs on Colab servers** (with GPU) - NOT your local machine\n",
    "2. **Local files are NOT automatically available** - You need to either:\n",
    "   - Clone the repo in the Colab runtime (recommended)\n",
    "   - Upload files manually via right-click ‚Üí \"Upload to Colab Session\"\n",
    "   - Mount Google Drive for persistent storage\n",
    "\n",
    "### To Connect:\n",
    "1. Click `Select Kernel` ‚Üí `Colab` ‚Üí `New Colab Server`\n",
    "2. Choose runtime type (T4 GPU recommended)\n",
    "3. Run the setup cells below\n",
    "\n",
    "---\n",
    "\n",
    "## Features\n",
    "- **SDXL Lightning**: 4-step inference using UNet checkpoints (recommended by ByteDance)\n",
    "- **ControlNet Depth**: Structure preservation using depth from `midas_depth` module\n",
    "- **T4 GPU Optimized**: Memory optimizations for 15GB VRAM\n",
    "\n",
    "## Pipeline Role\n",
    "```\n",
    "SyncDreamer (16 views) ‚Üí 3DGS ‚Üí Render ‚Üí [This Module] ‚Üí Refined Views ‚Üí Back to 3DGS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730410e",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup & Installation\n",
    "\n",
    "**Important**: Since the Colab runtime is remote, we need to:\n",
    "1. Clone the Glimpse3D repository into the Colab environment\n",
    "2. Install dependencies on the remote runtime\n",
    "3. Set up caching to avoid re-downloading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999dde04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install -q diffusers>=0.25.0 transformers>=4.36.0 accelerate>=0.25.0\n",
    "!pip install -q xformers  # Memory-efficient attention\n",
    "!pip install -q huggingface_hub safetensors\n",
    "!pip install -q timm scipy  # For MiDaS depth\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone Glimpse3D repository into Colab runtime\n",
    "# NOTE: This clones to the COLAB SERVER, not your local machine!\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Define paths\n",
    "COLAB_ROOT = \"/content\"\n",
    "REPO_PATH = f\"{COLAB_ROOT}/Glimpse-3D\"\n",
    "\n",
    "# Clone if not exists\n",
    "if not os.path.exists(REPO_PATH):\n",
    "    print(\"üì• Cloning Glimpse3D repository to Colab runtime...\")\n",
    "    !git clone https://github.com/varunaditya27/Glimpse3D.git {REPO_PATH}\n",
    "    print(\"‚úÖ Repository cloned!\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists in Colab runtime\")\n",
    "    # Optionally pull latest changes\n",
    "    # !cd {REPO_PATH} && git pull\n",
    "\n",
    "# Add to Python path\n",
    "if REPO_PATH not in sys.path:\n",
    "    sys.path.insert(0, REPO_PATH)\n",
    "\n",
    "# Change working directory\n",
    "os.chdir(REPO_PATH)\n",
    "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
    "print(f\"üìÇ Files in ai_modules/: {os.listdir('ai_modules') if os.path.exists('ai_modules') else 'NOT FOUND'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd01546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure caching and environment\n",
    "# This persists models across sessions if using Google Drive\n",
    "import os\n",
    "\n",
    "# Option 1: Use Colab's /content directory (lost on disconnect)\n",
    "os.environ[\"HF_HOME\"] = \"/content/hf_cache\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/content/hf_cache\"\n",
    "os.makedirs(\"/content/hf_cache\", exist_ok=True)\n",
    "\n",
    "# Option 2: Mount Google Drive for persistent cache (recommended for large models)\n",
    "# Uncomment below to use Google Drive:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# os.environ[\"HF_HOME\"] = \"/content/drive/MyDrive/hf_cache\"\n",
    "# os.makedirs(os.environ[\"HF_HOME\"], exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Cache directory: {os.environ['HF_HOME']}\")\n",
    "print(\"üí° Tip: Mount Google Drive (uncomment above) to persist models across sessions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ce8d8d",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Test Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c37cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports from diffusion module\n",
    "try:\n",
    "    from ai_modules.diffusion import (\n",
    "        EnhanceService,\n",
    "        EnhanceConfig,\n",
    "        enhance_view,\n",
    "        MemoryConfig,\n",
    "        get_memory_status,\n",
    "        print_memory_report,\n",
    "        PromptBuilder,\n",
    "    )\n",
    "    print(\"‚úÖ Diffusion module imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f44dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports from midas_depth module\n",
    "try:\n",
    "    from ai_modules.midas_depth import (\n",
    "        estimate_depth,\n",
    "        estimate_depth_confidence,\n",
    "        save_depth_visualization,\n",
    "        DepthEstimator,\n",
    "    )\n",
    "    print(\"‚úÖ MiDaS depth module imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab855b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU memory before loading models\n",
    "print_memory_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc73405",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Get Test Image\n",
    "\n",
    "**Option A**: Download a sample image from the web  \n",
    "**Option B**: Upload your own local image using VS Code Colab extension:\n",
    "  - Right-click your local file in VS Code Explorer\n",
    "  - Select \"Upload to Colab Session\"\n",
    "  - File will appear in `/content/`\n",
    "\n",
    "**Option C**: Mount Google Drive and use images from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c132c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create test directory in Colab runtime\n",
    "os.makedirs('/content/test_images', exist_ok=True)\n",
    "os.makedirs('/content/outputs', exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# CHOOSE YOUR IMAGE SOURCE:\n",
    "# ============================================================\n",
    "\n",
    "# Option A: Download sample image from web\n",
    "test_image_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/input_image_vermeer.png\"\n",
    "test_image_path = \"/content/test_images/test_render.png\"\n",
    "\n",
    "if not os.path.exists(test_image_path):\n",
    "    print(\"üì• Downloading sample test image...\")\n",
    "    urllib.request.urlretrieve(test_image_url, test_image_path)\n",
    "    print(f\"‚úÖ Downloaded to: {test_image_path}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Using existing: {test_image_path}\")\n",
    "\n",
    "# Option B: Use uploaded file (via VS Code right-click ‚Üí \"Upload to Colab Session\")\n",
    "# Uncomment and modify path:\n",
    "# test_image_path = \"/content/your_uploaded_image.png\"\n",
    "\n",
    "# Option C: Use file from mounted Google Drive\n",
    "# test_image_path = \"/content/drive/MyDrive/your_image.png\"\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "# Display test image\n",
    "print(f\"\\nüìÇ Test image path: {test_image_path}\")\n",
    "test_img = Image.open(test_image_path)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(test_img)\n",
    "plt.title(f\"Test Input Image\\nSize: {test_img.size}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb41e5",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Test MiDaS Depth Estimation\n",
    "\n",
    "First, let's verify the `midas_depth` module integration works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac814824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Estimate depth using midas_depth module\n",
    "print(\"üîç Estimating depth...\")\n",
    "depth_map = estimate_depth(test_image_path, model_type=\"MiDaS_small\")\n",
    "\n",
    "print(f\"‚úÖ Depth map shape: {depth_map.shape}\")\n",
    "print(f\"   Depth range: [{depth_map.min():.4f}, {depth_map.max():.4f}]\")\n",
    "\n",
    "# Visualize depth\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].imshow(test_img)\n",
    "axes[0].set_title(\"Input Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(depth_map, cmap='magma')\n",
    "axes[1].set_title(\"Depth Map (MiDaS)\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test depth confidence estimation\n",
    "rgb_array = np.array(test_img)\n",
    "confidence = estimate_depth_confidence(depth_map, rgb_array)\n",
    "\n",
    "print(f\"‚úÖ Confidence map shape: {confidence.shape}\")\n",
    "print(f\"   Confidence range: [{confidence.min():.4f}, {confidence.max():.4f}]\")\n",
    "\n",
    "# Visualize confidence\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].imshow(test_img)\n",
    "axes[0].set_title(\"Input\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(depth_map, cmap='magma')\n",
    "axes[1].set_title(\"Depth\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(confidence, cmap='viridis')\n",
    "axes[2].set_title(\"Confidence (bright=reliable)\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e652e56",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Load Enhancement Service\n",
    "\n",
    "Now let's load the SDXL Lightning + ControlNet pipeline.\n",
    "\n",
    "**‚ö†Ô∏è This downloads ~10GB of models on first run!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration for T4 GPU\n",
    "config = EnhanceConfig.for_t4_gpu()\n",
    "\n",
    "print(\"Enhancement Configuration:\")\n",
    "print(f\"  Device: {config.device}\")\n",
    "print(f\"  Lightning steps: {config.lightning_steps}\")\n",
    "print(f\"  ControlNet: {config.use_controlnet}\")\n",
    "print(f\"  Strength: {config.strength}\")\n",
    "print(f\"  Memory optimization: {config.optimize_memory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e4ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load the enhancement service (downloads models automatically)\n",
    "# This may take 5-10 minutes on first run\n",
    "\n",
    "service = EnhanceService(config=config)\n",
    "service.load()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ Enhancement service loaded!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcba4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check memory after loading\n",
    "print_memory_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1322656e",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Test Enhancement\n",
    "\n",
    "Let's enhance our test image with different settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c75e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Basic enhancement with auto-depth\n",
    "enhanced = service.enhance(\n",
    "    image=test_image_path,\n",
    "    prompt=\"high quality 3D render, detailed texture, photorealistic, studio lighting\",\n",
    "    seed=42  # For reproducibility\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Enhancement complete!\")\n",
    "print(f\"   Output size: {enhanced.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91012bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs enhanced\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "axes[0].imshow(test_img)\n",
    "axes[0].set_title(\"Original\", fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(enhanced)\n",
    "axes[1].set_title(\"Enhanced (SDXL Lightning + ControlNet)\", fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a62e46",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Test with Pre-computed Depth\n",
    "\n",
    "Using depth from `midas_depth` module for better control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff86aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Enhancement with pre-computed depth (skips auto-depth)\n",
    "enhanced_with_depth = service.enhance(\n",
    "    image=test_image_path,\n",
    "    depth_map=depth_map,  # From midas_depth\n",
    "    prompt=\"photorealistic 3D model, detailed surface texture, professional rendering\",\n",
    "    controlnet_scale=0.6,  # Stronger structure preservation\n",
    "    strength=0.7,  # Less change from original\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Enhancement with pre-computed depth complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff2955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all versions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].imshow(test_img)\n",
    "axes[0].set_title(\"Original\", fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(enhanced)\n",
    "axes[1].set_title(\"Enhanced (auto-depth)\", fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(enhanced_with_depth)\n",
    "axes[2].set_title(\"Enhanced (pre-computed depth, stronger control)\", fontsize=12)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bef66b",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Test Confidence-Weighted Blending\n",
    "\n",
    "Blend enhanced and original based on depth confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7686f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Enhancement with confidence-weighted blending\n",
    "# Preserves original in low-confidence (uncertain depth) regions\n",
    "enhanced_blended = service.enhance_with_depth_confidence(\n",
    "    image=test_image_path,\n",
    "    prompt=\"high quality 3D render, detailed texture\",\n",
    "    blend_with_original=True,\n",
    "    confidence_threshold=0.5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Confidence-weighted enhancement complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7578123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare blended vs full enhancement\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axes[0].imshow(test_img)\n",
    "axes[0].set_title(\"Original\", fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(enhanced)\n",
    "axes[1].set_title(\"Full Enhancement\", fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(enhanced_blended)\n",
    "axes[2].set_title(\"Confidence-Weighted Blend\", fontsize=12)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1731feb3",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Test Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937637c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available templates\n",
    "builder = PromptBuilder(template=\"default\")\n",
    "print(\"Available prompt templates:\")\n",
    "for template in builder.list_templates():\n",
    "    info = builder.get_template_info(template)\n",
    "    print(f\"  ‚Ä¢ {template}: {info['base_prompt'][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt using template\n",
    "builder = PromptBuilder(template=\"photorealistic\")\n",
    "prompt, negative = builder.build(\n",
    "    subject=\"a detailed 3D model\",\n",
    "    extra_modifiers=[\"soft shadows\", \"ambient occlusion\"]\n",
    ")\n",
    "\n",
    "print(\"Generated Prompt:\")\n",
    "print(f\"  Positive: {prompt}\")\n",
    "print(f\"  Negative: {negative}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cab3ab",
   "metadata": {},
   "source": [
    "## üîü Test Batch Enhancement\n",
    "\n",
    "Simulate enhancing multiple views (as in the pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple test images (simulating rendered views)\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "test_images = []\n",
    "for i in range(4):\n",
    "    # Create variations to simulate different views\n",
    "    img = test_img.copy()\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(0.9 + i * 0.1)  # Vary brightness\n",
    "    test_images.append(img)\n",
    "\n",
    "print(f\"Created {len(test_images)} test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17749919",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Batch enhancement with progress callback\n",
    "def progress_callback(current, total):\n",
    "    print(f\"  Processing view {current}/{total}...\")\n",
    "\n",
    "print(\"Starting batch enhancement...\")\n",
    "enhanced_batch = service.enhance_batch(\n",
    "    images=test_images,\n",
    "    prompt=\"high quality 3D render, detailed texture\",\n",
    "    progress_callback=progress_callback,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Batch enhancement complete! {len(enhanced_batch)} images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b08d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display batch results\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(4):\n",
    "    axes[0, i].imshow(test_images[i])\n",
    "    axes[0, i].set_title(f\"Original {i+1}\")\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(enhanced_batch[i])\n",
    "    axes[1, i].set_title(f\"Enhanced {i+1}\")\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle(\"Batch Enhancement Results\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4812b9",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404cc61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save enhanced images to Colab runtime\n",
    "output_dir = \"/content/outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "enhanced.save(f\"{output_dir}/enhanced_basic.png\")\n",
    "enhanced_with_depth.save(f\"{output_dir}/enhanced_with_depth.png\")\n",
    "enhanced_blended.save(f\"{output_dir}/enhanced_blended.png\")\n",
    "\n",
    "for i, img in enumerate(enhanced_batch):\n",
    "    img.save(f\"{output_dir}/enhanced_batch_{i+1}.png\")\n",
    "\n",
    "# Save comparison\n",
    "from ai_modules.diffusion.image_utils import save_comparison\n",
    "save_comparison(\n",
    "    original=test_img,\n",
    "    enhanced=enhanced,\n",
    "    output_path=f\"{output_dir}/comparison.png\",\n",
    "    depth=depth_map\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Results saved to {output_dir}/\")\n",
    "!ls -la {output_dir}\n",
    "\n",
    "# ============================================================\n",
    "# DOWNLOAD RESULTS TO LOCAL MACHINE:\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì• TO DOWNLOAD RESULTS TO YOUR LOCAL MACHINE:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Option 1: In VS Code, use Command Palette ‚Üí 'Colab: Download File'\")\n",
    "print(\"Option 2: Copy to Google Drive:\")\n",
    "print(f\"          !cp -r {output_dir}/* /content/drive/MyDrive/glimpse3d_outputs/\")\n",
    "print(\"Option 3: Use the code cell below to create a zip file\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Create a zip file for easy download\n",
    "import shutil\n",
    "\n",
    "zip_path = \"/content/enhanced_outputs\"\n",
    "shutil.make_archive(zip_path, 'zip', output_dir)\n",
    "print(f\"‚úÖ Created: {zip_path}.zip\")\n",
    "print(f\"üì• Download via VS Code: Right-click the file in Colab Files panel\")\n",
    "\n",
    "# Optional: Copy to Google Drive (uncomment if Drive is mounted)\n",
    "# !cp {zip_path}.zip /content/drive/MyDrive/\n",
    "# print(\"‚úÖ Copied to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04e9912",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c57bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unload models to free GPU memory\n",
    "service.unload()\n",
    "\n",
    "# Check memory after unload\n",
    "print_memory_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d5b26",
   "metadata": {},
   "source": [
    "## üìã Summary\n",
    "\n",
    "### VS Code Colab Extension Notes:\n",
    "- ‚úÖ **Kernel runs on Colab servers** with GPU access\n",
    "- ‚úÖ **Clone repo to runtime** - Required since local files aren't synced\n",
    "- ‚úÖ **Upload files manually** - Right-click ‚Üí \"Upload to Colab Session\"\n",
    "- ‚úÖ **Mount Google Drive** - For persistent storage across sessions\n",
    "- ‚úÖ **Download results** - Via Command Palette or copy to Drive\n",
    "\n",
    "### What We Tested:\n",
    "1. ‚úÖ Module imports\n",
    "2. ‚úÖ MiDaS depth estimation integration\n",
    "3. ‚úÖ Depth confidence estimation\n",
    "4. ‚úÖ SDXL Lightning + ControlNet enhancement\n",
    "5. ‚úÖ Enhancement with pre-computed depth\n",
    "6. ‚úÖ Confidence-weighted blending\n",
    "7. ‚úÖ Prompt templates\n",
    "8. ‚úÖ Batch enhancement\n",
    "\n",
    "### Performance on T4 GPU:\n",
    "- Model loading: ~3-5 minutes (first time)\n",
    "- Per-image enhancement: ~8-10 seconds\n",
    "- VRAM usage: ~12GB\n",
    "\n",
    "### Pipeline Integration:\n",
    "```python\n",
    "from ai_modules.midas_depth import estimate_depth\n",
    "from ai_modules.diffusion import EnhanceService\n",
    "\n",
    "# In the refinement loop:\n",
    "for view in rendered_views:\n",
    "    depth = estimate_depth(view)\n",
    "    enhanced = service.enhance(view, depth_map=depth)\n",
    "    # Back-project enhanced view to 3DGS...\n",
    "```\n",
    "\n",
    "### Troubleshooting:\n",
    "- **\"Module not found\"**: Make sure you ran the clone cell first\n",
    "- **\"File not found\"**: Upload file via right-click or check path\n",
    "- **OOM errors**: Restart runtime and use `config.optimize_memory = True`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
