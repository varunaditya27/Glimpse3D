# ğŸ¯ SyncDreamer Module for Glimpse3D

Multi-view consistent image generation from a single input image.

## Overview

SyncDreamer generates **16 consistent multi-view images** from a single input image, which are then used by the Glimpse3D pipeline for 3D reconstruction.

## ğŸ““ Inference Notebooks

| Notebook | Description |
|----------|-------------|
| [Glimpse3D_SyncDreamer_Inference.ipynb](../../notebooks/Glimpse3D_SyncDreamer_Inference.ipynb) | **Recommended** - Uses this module directly. Run via VS Code + Colab Extension |
| [SyncDreamer_Colab_Inference.ipynb](../../notebooks/SyncDreamer_Colab_Inference.ipynb) | Standalone - Clones original SyncDreamer repo |

### Why SyncDreamer over Zero123?

| Aspect | Zero123 | SyncDreamer |
|--------|---------|-------------|
| **VRAM Usage** | ~24GB+ | ~12GB |
| **Multi-view Consistency** | Per-view generation (can be inconsistent) | Synchronized generation (consistent) |
| **Output** | Single view at a time | 16 views simultaneously |
| **Speed** | Multiple passes needed | Single pass for all views |

## Installation

### Prerequisites

```bash
pip install torch torchvision omegaconf pytorch-lightning
pip install rembg  # For background removal (optional but recommended)
```

### Download Checkpoints

You need **two files** for SyncDreamer to work:

#### 1. SyncDreamer Model (~5.2GB)
**Google Drive:** https://drive.google.com/file/d/1ypyD5WXxAnsWjnHgAfOAGolV0Zd9kpam/view

#### 2. CLIP ViT-L-14 Encoder (~890MB) âš ï¸ Required
**Hugging Face:** https://huggingface.co/camenduru/SyncDreamer/resolve/main/ViT-L-14.pt

Download via PowerShell:
```powershell
# Download ViT-L-14.pt
Invoke-WebRequest -Uri "https://huggingface.co/camenduru/SyncDreamer/resolve/main/ViT-L-14.pt" -OutFile "ai_modules/sync_dreamer/ckpt/ViT-L-14.pt"
```

Or via curl:
```bash
curl -L https://huggingface.co/camenduru/SyncDreamer/resolve/main/ViT-L-14.pt -o ai_modules/sync_dreamer/ckpt/ViT-L-14.pt
```

#### Final checkpoint folder:
```
ai_modules/sync_dreamer/ckpt/
â”œâ”€â”€ syncdreamer-pretrain.ckpt  (~5.2GB)
â””â”€â”€ ViT-L-14.pt                (~890MB)
```

## Usage

### Quick Start

```python
from ai_modules.sync_dreamer import generate_multiview

# Generate 16 views from a single image
output_paths = generate_multiview(
    image_path="input.png",      # RGBA image with transparent background
    output_dir="outputs/views",
    elevation=30.0,              # Input camera elevation (degrees)
    seed=42
)
print(f"Generated {len(output_paths)} views")
```

### Using the Service Class

```python
from ai_modules.sync_dreamer import SyncDreamerService

# Initialize service
service = SyncDreamerService()

# Load model (done automatically on first generate call)
service.load_model()

# Generate views
images = service.generate(
    image="input.png",
    elevation=30.0,
    cfg_scale=2.0,
    sample_steps=50,
    batch_view_num=8  # Lower this if you have less VRAM
)

# Save with custom naming
for i, img in enumerate(images):
    img.save(f"view_{i:02d}.png")

# Free GPU memory when done
service.unload_model()
```

### Background Removal

For best results, input images should have transparent backgrounds:

```python
from ai_modules.sync_dreamer import segment_foreground
from PIL import Image

# Remove background
image = Image.open("photo.jpg")
rgba_image = segment_foreground(image, method="rembg")
rgba_image.save("input.png")
```

## Output Views

SyncDreamer generates 16 views at fixed camera positions:

| Views 0-7 | Views 8-15 |
|-----------|------------|
| Elevation: 30Â° | Elevation: -20Â° |
| Azimuths: 0Â°, 45Â°, 90Â°, 135Â°, 180Â°, 225Â°, 270Â°, 315Â° | Same azimuths |

```
View Layout (4x4 grid):
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”
â”‚ 0  â”‚ 1  â”‚ 2  â”‚ 3  â”‚  â† Elevation 30Â°
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤
â”‚ 4  â”‚ 5  â”‚ 6  â”‚ 7  â”‚  â† Elevation 30Â°
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤
â”‚ 8  â”‚ 9  â”‚ 10 â”‚ 11 â”‚  â† Elevation -20Â°
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¤
â”‚ 12 â”‚ 13 â”‚ 14 â”‚ 15 â”‚  â† Elevation -20Â°
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜
```

## API Reference

### `generate_multiview(image_path, output_dir, **kwargs)`

Quick function for multi-view generation.

**Parameters:**
- `image_path` (str): Path to input image
- `output_dir` (str): Directory for output images
- `elevation` (float): Input view elevation, default 30.0
- `crop_size` (int): Foreground crop size, default 200
- `cfg_scale` (float): Guidance scale, default 2.0
- `seed` (int): Random seed, default 42

**Returns:** List of output file paths

### `SyncDreamerService`

Main service class for inference.

**Methods:**
- `load_model()`: Load model to GPU
- `unload_model()`: Free GPU memory
- `generate(image, **kwargs)`: Generate 16 views
- `generate_and_save(image, output_dir, **kwargs)`: Generate and save to disk

### Utility Functions

- `segment_foreground(image)`: Remove background
- `preprocess_for_syncdreamer(image)`: Prepare image for inference
- `get_camera_matrices(elevations, azimuths)`: Get camera transforms
- `views_to_video(image_paths, output_path)`: Create turntable video

## Integration with Glimpse3D Pipeline

```
Input Image
    â†“
Background Removal (segment_foreground)
    â†“
SyncDreamer â†’ 16 Consistent Views
    â†“
MiDaS Depth â†’ Depth Maps
    â†“
Gaussian Splatting Reconstruction
    â†“
SDXL Enhancement Loop
    â†“
Refined 3D Model
```

## VRAM Optimization

For GPUs with limited VRAM:

```python
# Use smaller batch size
images = service.generate(
    image,
    batch_view_num=4,  # Default is 8, use 4 for <12GB VRAM
    sample_num=1       # Generate 1 set instead of multiple
)
```

## File Structure

```
ai_modules/sync_dreamer/
â”œâ”€â”€ __init__.py           # Module exports
â”œâ”€â”€ inference.py          # Main inference service
â”œâ”€â”€ utils_syncdreamer.py  # Utility functions
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ ckpt/                 # Model checkpoints
â”‚   â”œâ”€â”€ syncdreamer-pretrain.ckpt
â”‚   â””â”€â”€ ViT-L-14.pt
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ syncdreamer.yaml  # Model configuration
â””â”€â”€ ldm/                  # Core model code (from SyncDreamer repo)
    â”œâ”€â”€ util.py
    â”œâ”€â”€ base_utils.py
    â”œâ”€â”€ models/
    â”‚   â””â”€â”€ diffusion/
    â””â”€â”€ modules/
```

## Troubleshooting

### "Checkpoint not found"
Download both checkpoints:
- `syncdreamer-pretrain.ckpt` from [Google Drive](https://drive.google.com/file/d/1ypyD5WXxAnsWjnHgAfOAGolV0Zd9kpam/view)
- `ViT-L-14.pt` from [Hugging Face](https://huggingface.co/camenduru/SyncDreamer/resolve/main/ViT-L-14.pt)

### "CUDA out of memory"
- Reduce `batch_view_num` to 4 or 2
- Use `sample_num=1`
- Close other GPU applications

### "No module named 'ldm'"
The ldm module should be in `ai_modules/sync_dreamer/ldm/`. Check that all files were copied correctly.

## License

SyncDreamer is released under the MIT License.
Original repository: https://github.com/liuyuan-pal/SyncDreamer

## Citation

```bibtex
@article{liu2023syncdreamer,
  title={SyncDreamer: Generating Multiview-consistent Images from a Single-view Image},
  author={Liu, Yuan and Lin, Cheng and Zeng, Zijiao and Long, Xiaoxiao and Liu, Lingjie and Komura, Taku and Wang, Wenping},
  journal={arXiv preprint arXiv:2309.03453},
  year={2023}
}
```
