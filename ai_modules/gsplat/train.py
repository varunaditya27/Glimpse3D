import argparse
import sys
import os
import torch
import logging
from pathlib import Path
from PIL import Image
import numpy as np

# Add parent directory to path to allow absolute imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))

from ai_modules.gsplat.reconstruct import load_triposr_model, preprocess_image, run_inference, sample_and_export
from ai_modules.gsplat.utils_gs import load_ply, save_ply
from ai_modules.gsplat.camera_utils import build_intrinsics
from ai_modules.gsplat.optimize import refine_model
# Configure Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Glimpse3D-Train")

try:
    from ai_modules.sync_dreamer.utils_syncdreamer import SYNCDREAMER_CAMERAS, get_camera_matrices
    HAS_SYNCDREAMER = True
except ImportError as e:
    HAS_SYNCDREAMER = False
    logger.warning(f"SyncDreamer utils not found ({e}). Multi-view refinement will be disabled.")

def train_pipeline(image_path: str, output_dir: str, iterations: int = 100, ply_path: str = None, views_dir: str = None):
    """
    End-to-End Pipeline:
    1. Reconstruction (Image -> PLY)
    2. Optimization (PLY + Image -> Refined PLY)
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # --- PHASE 1: RECONSTRUCTION ---
    logger.info("=== Phase 1: Cold Start Reconstruction ===")
    
    # Logic: If ply_path is provided, use it. Else check output_dir. Else reconstruct.
    initial_ply_path = ply_path
    
    # If no explicit path, define default location
    if initial_ply_path is None:
        initial_ply_path = os.path.join(output_dir, "initial_splat.ply")

    if os.path.exists(initial_ply_path):
        logger.info(f"Initial PLY found at {initial_ply_path}, skipping reconstruction.")
    else:
        try:
            logger.info("Loading Inference Model...")
            # Handle import error/mock
            try:
                model_inf = load_triposr_model()
            except Exception:
                model_inf = None # Fallback inside run_inference
                
            logger.info("Processing Image...")
            img_tensor = preprocess_image(image_path)
            
            logger.info("Running Inference...")
            mesh = run_inference(model_inf, img_tensor)
            
            logger.info("Exporting Initial PLY...")
            sample_and_export(mesh, initial_ply_path)
        except Exception as e:
            logger.error(f"Reconstruction Failed: {e}")
            return

    # --- PHASE 3: OPTIMIZATION ---
    logger.info("=== Phase 3: Optimization Loop ===")
    
    # 1. Load the Model
    logger.info(f"Loading Gaussian Model from {initial_ply_path}")
    gs_model = load_ply(initial_ply_path)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    gs_model.to(device)
    
    # 2. Prepare Training Data
    target_images = []
    cameras = []
    
    # Common Camera Params
    H, W = 512, 512 # Default for TripoSR/SyncDreamer usually 256 but let's stick to 256 for MV
    
    # Check if we can use Multi-View
    if views_dir and os.path.exists(views_dir) and HAS_SYNCDREAMER:
        logger.info(f"Loading Multi-View Data from {views_dir}")
        import glob
        
        # SyncDreamer views are usually 256x256
        H, W = 256, 256
        fov_y = 30.0 * (H / 256.0) # Approx FOV for SyncDreamer crops
        # Note: SyncDreamer uses specific FOV (~30 deg). 
        # Ref: SyncDreamer paper uses 30 degrees elevation, FOV 30.
        
        K = build_intrinsics(30.0, W, H).to(device)
        
        # Get Camera Matrices
        elevations = SYNCDREAMER_CAMERAS['elevations']
        azimuths = SYNCDREAMER_CAMERAS['azimuths']
        # radius = SYNCDREAMER_CAMERAS['radius'] # Matrix gen handles radius
        
        w2c_matrices = get_camera_matrices(elevations, azimuths, radius=1.5)
        
        # Load Images
        # Assuming filenames format from SyncDreamer: view_00_elev30_azim0.png
        # Or just sorted by name if generated by our pipeline
        sorted_files = sorted(glob.glob(os.path.join(views_dir, "enhanced_view_*.png")))
        if not sorted_files:
             # Try non-enhanced
             sorted_files = sorted(glob.glob(os.path.join(views_dir, "view_*.png")))
             
        if len(sorted_files) >= 16:
            logger.info(f"Found {len(sorted_files)} views. Using top 16 for SyncDreamer positions.")
            
            for i in range(16):
                if i >= len(sorted_files): break
                
                img_path = sorted_files[i]
                
                # Load Image
                pil_img = Image.open(img_path).convert("RGB").resize((W, H))
                tensor_img = torch.from_numpy(np.array(pil_img)).float() / 255.0
                tensor_img = tensor_img.permute(2, 0, 1).to(device)
                target_images.append(tensor_img)
                
                # Load Camera
                # W2C matrix from utils needs to be converted to torch
                w2c_np = w2c_matrices[i]
                
                # Coordinate System Conversion if needed
                # OpenGL (Gsplat) vs PyTorch3D/SyncDreamer might differ.
                # Usually SyncDreamer is: X right, Y up, Z back (OpenGL style)?
                # Let's assume standard OpenGL for now.
                
                w2c = torch.from_numpy(w2c_np).float().to(device)
                
                cam_params = {
                    'image_height': H,
                    'image_width': W,
                    'K': K,
                    'w2c': w2c
                }
                cameras.append(cam_params)
        else:
            logger.warning(f"Found only {len(sorted_files)} views. Fallback to single view.")
            views_dir = None # Trigger fallback

    if not target_images: # Fallback to Single View (Input Image)
        logger.info("Using Single View (Input Image) for Optimization.")
        H, W = 512, 512
        fov_y = 60.0 # deg
        
        # Input Image as Ground Truth
        gt_pil = Image.open(image_path).convert("RGB").resize((W, H))
        gt_tensor = torch.from_numpy(np.array(gt_pil)).float() / 255.0
        gt_tensor = gt_tensor.permute(2, 0, 1).to(device)
        target_images.append(gt_tensor)
        
        K = build_intrinsics(fov_y, W, H).to(device)
        
        # Single View Camera (Front)
        w2c = torch.eye(4, device=device)
        w2c[2, 3] = 2.0 # Eye at Z=2
        w2c[2, 3] = -2.0 # Look at Z=-2 (Standard OpenGL view matrix logic requires invert)
        # Actually standard LookAt(eye=(0,0,2), center=(0,0,0), up=(0,1,0))
        # gives a view matrix that transforms world (0,0,0) to camera (0,0,-2).
        
        cam_params = {
            'image_height': H,
            'image_width': W,
            'K': K,
            'w2c': w2c
        }
        cameras.append(cam_params)
    
    # 3. Run Refine
    logger.info(f"Starting Refinement for {iterations} iterations...")
    try:
        refined_model = refine_model(
            gs_model,
            target_images,
            cameras,
            iterations=iterations
        )
        
        # 4. Save Final
        final_ply_path = os.path.join(output_dir, "final_refined.ply")
        logger.info(f"Saving final model to {final_ply_path}")
        save_ply(refined_model, final_ply_path)
        logger.info("Pipeline Complete!")
        
    except Exception as e:
        logger.error(f"Optimization Failed: {e}")
        import traceback
        traceback.print_exc()

def main():
    parser = argparse.ArgumentParser(description="Glimpse3D Training Pipeline")
    parser.add_argument("image", type=str, help="Input image path")
    parser.add_argument("--out", type=str, default="project_out", help="Output Directory")
    parser.add_argument("--iter", type=int, default=100, help="Optimization Iterations")
    parser.add_argument("--ply_path", type=str, default=None, help="Path to initial PLY (skips reconstruction)")
    parser.add_argument("--views_dir", type=str, default=None, help="Directory containing SyncDreamer generated views")
    
    args = parser.parse_args()
    
    if not os.path.exists(args.image):
        logger.error("Image not found")
        sys.exit(1)
        
    train_pipeline(args.image, args.out, args.iter, args.ply_path, args.views_dir)

if __name__ == "__main__":
    main()
